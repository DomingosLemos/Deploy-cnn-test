{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLNN_v01.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "i5PjZetq5X08",
        "QvIpODRc5YUe",
        "y9Yza1ir5YuX"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomingosLemos/Deploy-cnn-test/blob/main/DLNN_v01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvL02fSdjVfM",
        "outputId": "cfa77f42-b854-40ac-ad66-26f00c729d31"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXavUfmhoK5U",
        "outputId": "e5b2fa9d-d968-47e9-871b-cd8d0af3cf67"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfETxsFEjZyg",
        "outputId": "14b1dff8-cd9d-478e-cee8-e7206b43b285"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "import timeit\r\n",
        "\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  print(\r\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\r\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\r\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "\r\n",
        "def cpu():\r\n",
        "  with tf.device('/cpu:0'):\r\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\r\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\r\n",
        "    return tf.math.reduce_sum(net_cpu)\r\n",
        "\r\n",
        "def gpu():\r\n",
        "  with tf.device('/device:GPU:0'):\r\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\r\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\r\n",
        "    return tf.math.reduce_sum(net_gpu)\r\n",
        "  \r\n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\r\n",
        "cpu()\r\n",
        "gpu()\r\n",
        "\r\n",
        "# Run the op several times.\r\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\r\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\r\n",
        "print('CPU (s):')\r\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\r\n",
        "print(cpu_time)\r\n",
        "print('GPU (s):')\r\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\r\n",
        "print(gpu_time)\r\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "2.6847364949999815\n",
            "GPU (s):\n",
            "0.0375170690000175\n",
            "GPU speedup over CPU: 71x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLvSpNQqkT08"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import h5py\r\n",
        "import gc\r\n",
        "import tensorflow as tf\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras_preprocessing.image import ImageDataGenerator\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "from keras import optimizers\r\n",
        "from keras import regularizers\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras import Model\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from keras.constraints import maxnorm\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "\r\n",
        "#models\r\n",
        "from keras.applications.resnet50 import ResNet50\r\n",
        "from keras.applications.inception_v3 import InceptionV3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk1fVSGHp7WU",
        "outputId": "aee3ccdb-fe6b-4714-ec82-cfa3bef6e6d4"
      },
      "source": [
        "!7z x /content/drive/MyDrive/EDSA/images.zip -o./imagens/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/drive/MyDrive/EDSA/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 5132666035 bytes (4895 MiB)\n",
            "\n",
            "Extracting archive: /content/drive/MyDrive/EDSA/images.zip\n",
            "  4% 4096 Open\b\b\b\b\b\b\b\b\b\b\b\b\b\b              \b\b\b\b\b\b\b\b\b\b\b\b\b\b--\n",
            "Path = /content/drive/MyDrive/EDSA/images.zip\n",
            "Type = zip\n",
            "Physical Size = 5132666035\n",
            "64-bit = +\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% 710 - apple_pie/3468573.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 1365 - baby_back_ribs/2145496.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 1889 - baby_back_ribs/701934.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 2275 - baklava/1858825.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 2766 - baklava/3676885.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 3314 - beef_carpaccio/195418.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 3820 - beef_carpaccio/3865235.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 4272 - beef_tartare/206133.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 4794\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b  5% 5351 - beet_salad/2173711.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 5853 - beet_salad/423297.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 6466 - beignets/2639056.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 6866 - beignets/564090.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 7304 - bibimbap/205722.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 7774 - bibimbap/3642541.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 8332 - bread_pudding/2057209.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 8879 - bread_pudding/518791.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 9527 - breakfast_burrito/2909170.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 9816 - breakfast_burrito/478718.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 10369 - bruschetta/2368994.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 10850 - bruschetta/575963.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 11426 - caesar_salad/2462575.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 11910 - caesar_salad/56013.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 12327 - cannoli/2057528.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 12780 - cannoli/3742967.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 13388 - caprese_salad/2339891.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 13894 - caprese_salad/672751.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 14341 - carrot_cake/2243686.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 14791 - carrot_cake/376080.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 15351\b\b\b\b\b\b\b\b\b\b          \b\b\b\b\b\b\b\b\b\b 15% 15836 - ceviche/442941.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 16323 - cheesecake/2148420.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 16834 - cheesecake/3868436.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 17364 - cheese_plate/2167381.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 17846 - cheese_plate/477493.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 18433 - chicken_curry/2460096.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 18924 - chicken_curry/68606.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 19429 - chicken_quesadilla/2502965.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 19811 - chicken_quesadilla/3790020.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 20329 - chicken_wings/2054901.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 20836 - chicken_wings/44776.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 21472 - chocolate_cake/2642149.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 21915 - chocolate_cake/619975.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 22100 - chocolate_mousse/133254.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 22500 - chocolate_mousse/2659365.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 22785 - chocolate_mousse/3760569.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 23191 - churros/1616270.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 23390 - churros/2249944.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 23855 - churros/455030.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 24132 - clam_chowder/1373718.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 24799 - clam_chowder/379502.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 24912 - clam_chowder/655229.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 25401 - club_sandwich/2266796.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 25487 - club_sandwich/2639294.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 25845 - club_sandwich/3866537.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 26015 - club_sandwich/95569.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 26524 - crab_cakes/2662740.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 26762 - crab_cakes/3605007.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 27282 - creme_brulee/1776955.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 27633 - creme_brulee/300216.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 27821 - creme_brulee/39615.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 27860 - creme_brulee/512955.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 27866 - creme_brulee/530417.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 27871 - creme_brulee/553779.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 27876 - creme_brulee/567097.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 27882 - creme_brulee/59461.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 27887 - creme_brulee/60199.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 28142 - croque_madame/1362405.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 28385 - croque_madame/2248238.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 28632 - croque_madame/3162650.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 28872 - croque_madame/499558.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 29072 - cup_cakes/1144355.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 29275 - cup_cakes/182235.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 29485 - cup_cakes/2620690.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 29673 - cup_cakes/3325702.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 29792 - cup_cakes/398453.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 30019 - cup_cakes/975903.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 30150 - deviled_eggs/1379911.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 30299 - deviled_eggs/1872370.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 30438 - deviled_eggs/2374835.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 30585 - deviled_eggs/3039555.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 30728 - deviled_eggs/3525617.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 30878 - deviled_eggs/55117.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 31028 - deviled_eggs/985744.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 31163 - donuts/1486203.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 31291 - donuts/191469.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 31415 - donuts/2317067.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 31542 - donuts/2690174.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 31659 - donuts/3126988.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 31777 - donuts/3774342.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 31897 - donuts/608315.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 32020 - donuts/97163.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 32151 - dumplings/1316756.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 32286 - dumplings/1828047.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 32427 - dumplings/2325370.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 32508 - dumplings/263589.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 32577 - dumplings/2867404.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 32628 - dumplings/308735.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 32674 - dumplings/326133.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 32724 - dumplings/3489932.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 32778 - dumplings/3739057.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 32827 - dumplings/429692.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 32877 - dumplings/562765.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 33027 - dumplings/992650.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 33590 - edamame/3043840.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 34023 - edamame/977940.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 34654 - eggs_benedict/3247121.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 34677 - eggs_benedict/3315363.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 34683 - eggs_benedict/3339595.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 34689 - eggs_benedict/3360719.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 34694 - eggs_benedict/338210.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 34700 - eggs_benedict/3393493.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 34871 - eggs_benedict/465761.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 35045 - escargots/1037811.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 35182 - escargots/1503245.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 35316 - escargots/1917493.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 35445 - escargots/2415031.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 35571 - escargots/2902718.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 35692 - escargots/3316378.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 35811 - escargots/3714643.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 35928 - escargots/637190.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 36041 - falafel/102463.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 36160 - falafel/1464440.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 36283 - falafel/1879055.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 36412 - falafel/2330674.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 36498 - falafel/2655828.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 36560 - falafel/2930114.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 36619 - falafel/3116743.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 36670 - falafel/3298014.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 36715 - falafel/3445548.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 36752 - falafel/3575058.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 36790 - falafel/3726786.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 36824 - falafel/3838907.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 36857 - falafel/43498.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 36898 - falafel/58440.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 37008 - falafel/915881.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 37121 - filet_mignon/1270745.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 37226 - filet_mignon/1650659.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 37327 - filet_mignon/2091291.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 37413 - filet_mignon/2365130.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 37501 - filet_mignon/2663927.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 37659 - filet_mignon/3176155.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 37809 - filet_mignon/3802696.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 37933 - filet_mignon/699778.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 38087 - fish_and_chips/1187445.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 38239 - fish_and_chips/1774383.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 38357 - fish_and_chips/2178261.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 38616 - fish_and_chips/3119479.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 39019 - fish_and_chips/958644.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 39644 - foie_gras/3052927.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40011 - foie_gras/873597.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40179 - french_fries/1606755.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40202 - french_fries/1692647.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40208 - french_fries/1703753.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40211 - french_fries/1712331.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40215 - french_fries/17394.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40218 - french_fries/174977.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40221 - french_fries/1767923.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40226 - french_fries/1778153.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40231 - french_fries/1793704.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40236 - french_fries/1845621.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40244 - french_fries/1875986.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 40833 - french_fries/3762377.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 41299 - french_onion_soup/1809251.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 41814 - french_onion_soup/3704789.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 42386 - french_toast/2170004.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 42867 - french_toast/505316.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 43423 - fried_calamari/2176324.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 43861 - fried_calamari/503027.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 44362\b\b\b\b\b\b\b\b\b\b          \b\b\b\b\b\b\b\b\b\b 44% 44868 - fried_rice/3906173.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 45206 - frozen_yogurt/158926.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 45843 - frozen_yogurt/46459.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 45995 - frozen_yogurt/800505.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 46134 - garlic_bread/1331314.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 46259 - garlic_bread/1913273.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 46382 - garlic_bread/2275705.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 46501 - garlic_bread/2643891.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 46556 - garlic_bread/2850275.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 46728 - garlic_bread/3396235.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 46787 - garlic_bread/3578823.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 46793 - garlic_bread/3600544.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 46797 - garlic_bread/3608296.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 46801 - garlic_bread/3617115.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 46974 - garlic_bread/731088.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 47140 - gnocchi/1342194.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 47296 - gnocchi/1924475.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 47435 - gnocchi/2532851.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 47579 - gnocchi/3123358.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 47728 - gnocchi/3526814.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 47881 - gnocchi/503690.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 48023 - gnocchi/910082.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 48150 - greek_salad/1402516.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 48278 - greek_salad/1895312.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 48402 - greek_salad/2272897.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 48531 - greek_salad/2772598.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 48662 - greek_salad/3311271.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 48795 - greek_salad/3723380.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 48926 - greek_salad/604212.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 49053 - grilled_cheese_sandwich/1005927.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 49191 - grilled_cheese_sandwich/1448575.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 49334 - grilled_cheese_sandwich/1925125.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 49457 - grilled_cheese_sandwich/231786.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 49649 - grilled_cheese_sandwich/314341.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 49791 - grilled_cheese_sandwich/462717.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 49928 - grilled_cheese_sandwich/703555.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 50034 - grilled_cheese_sandwich/96260.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 50159 - grilled_salmon/1453246.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 50274 - grilled_salmon/1865874.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 50369 - grilled_salmon/2152214.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 50374 - grilled_salmon/2167171.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 50379 - grilled_salmon/2179450.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 50384 - grilled_salmon/2200219.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 50873 - grilled_salmon/3902581.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 51457 - guacamole/2497114.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 51633 - guacamole/3216409.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 51785 - guacamole/3681376.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 51917 - guacamole/600690.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 52048 - guacamole/984681.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 52187 - gyoza/1559054.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 52318 - gyoza/2058207.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 52327 - gyoza/2112798.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 52331 - gyoza/2125398.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 52336 - gyoza/214268.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 52535 - gyoza/2822254.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 52688 - gyoza/3323608.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 52823 - gyoza/381963.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 52947 - gyoza/667445.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 53074 - hamburger/1041547.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 53190 - hamburger/1510284.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 53310 - hamburger/1950289.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 53423 - hamburger/2341674.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 53545 - hamburger/286323.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 53674 - hamburger/3354472.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 53801 - hamburger/3811038.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 53926 - hamburger/608198.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 54050 - hamburger/991372.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 54181 - hot_and_sour_soup/1346061.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 54291 - hot_and_sour_soup/1706522.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 54356 - hot_and_sour_soup/2005531.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 54421 - hot_and_sour_soup/2266943.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 54475 - hot_and_sour_soup/2418522.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 54516 - hot_and_sour_soup/2606898.jpg"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RSCOdfZKNbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af2712d-af1d-4f1c-af58-c4df204dd1d0"
      },
      "source": [
        "!pip install split-folders\r\n",
        "import splitfolders\r\n",
        "splitfolders.ratio('/content/images', output=\"output\", seed=1337, ratio=(.7, .2, .1)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/5f/3c2b2f7ea5e047c8cdc3bb00ae582c5438fcdbbedcc23b3cc1c2c7aae642/split_folders-0.4.3-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying files: 101000 files [02:28, 678.66 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g97IGfJkjvyP"
      },
      "source": [
        "**Baseline Model Development**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXnM1OeMjvkC"
      },
      "source": [
        "Model 1 - Simple Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxb5VB_ZkT4W",
        "outputId": "6cae4105-a9f5-4e30-f04c-cec9fa1e7078"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator=valid_datagen.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 70700 images belonging to 101 classes.\n",
            "Found 20200 images belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMZ61toPkT1E",
        "outputId": "4bb0cca4-096d-44a9-ef75-dd97747a1ddd"
      },
      "source": [
        "X_train, y_train = train_generator.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_1 = Sequential()\r\n",
        "\r\n",
        "baseline_model_1.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_1.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_1.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_1.add(Dense(2048, activation='relu'))\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_1.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 62, 62, 128)       3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 31, 31, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 123008)            0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 2048)              251922432 \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 101)               206949    \n",
            "=================================================================\n",
            "Total params: 252,132,965\n",
            "Trainable params: 252,132,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yht656TKlytu"
      },
      "source": [
        "opt_1 = Adam()\r\n",
        "\r\n",
        "baseline_model_1.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_1,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62uPuYyulyqG",
        "outputId": "730fdeb0-6b19-462e-a01f-7d6d2c340762"
      },
      "source": [
        "X_val, y_val = valid_generator.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_1 = baseline_model_1.fit_generator(train_generator,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_1.save('food_baseline_model_1.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 48s 300ms/step - loss: 8.7708 - acc: 0.0122 - val_loss: 4.5827 - val_acc: 0.0141\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 48s 299ms/step - loss: 4.4965 - acc: 0.0276 - val_loss: 4.3247 - val_acc: 0.0672\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 50s 311ms/step - loss: 4.2067 - acc: 0.0680 - val_loss: 4.1898 - val_acc: 0.0766\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 50s 312ms/step - loss: 4.0520 - acc: 0.1018 - val_loss: 4.0187 - val_acc: 0.1016\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 50s 311ms/step - loss: 3.8542 - acc: 0.1373 - val_loss: 4.0117 - val_acc: 0.1125\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 50s 311ms/step - loss: 3.6295 - acc: 0.1967 - val_loss: 4.0255 - val_acc: 0.1000\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 49s 305ms/step - loss: 3.4268 - acc: 0.2326 - val_loss: 3.7935 - val_acc: 0.1344\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 50s 310ms/step - loss: 3.1783 - acc: 0.3018 - val_loss: 3.9311 - val_acc: 0.1406\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 49s 304ms/step - loss: 2.9990 - acc: 0.3463 - val_loss: 4.0956 - val_acc: 0.1094\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 48s 303ms/step - loss: 2.6866 - acc: 0.4184 - val_loss: 4.1591 - val_acc: 0.1125\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 48s 298ms/step - loss: 2.5045 - acc: 0.4609 - val_loss: 4.0576 - val_acc: 0.1281\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 47s 296ms/step - loss: 2.2909 - acc: 0.5097 - val_loss: 4.1499 - val_acc: 0.1219\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 48s 300ms/step - loss: 2.1542 - acc: 0.5326 - val_loss: 4.3007 - val_acc: 0.1047\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 48s 301ms/step - loss: 1.8930 - acc: 0.5994 - val_loss: 4.2612 - val_acc: 0.1109\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 48s 302ms/step - loss: 1.7010 - acc: 0.6390 - val_loss: 4.3541 - val_acc: 0.1406\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 49s 303ms/step - loss: 1.5622 - acc: 0.6697 - val_loss: 4.3888 - val_acc: 0.1453\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 49s 305ms/step - loss: 1.3905 - acc: 0.7146 - val_loss: 4.3690 - val_acc: 0.1453\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 48s 300ms/step - loss: 1.2572 - acc: 0.7419 - val_loss: 4.6398 - val_acc: 0.1234\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 48s 302ms/step - loss: 1.1282 - acc: 0.7633 - val_loss: 4.6782 - val_acc: 0.1250\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 47s 295ms/step - loss: 1.0008 - acc: 0.7929 - val_loss: 4.8325 - val_acc: 0.1250\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 47s 293ms/step - loss: 0.9086 - acc: 0.8145 - val_loss: 5.0314 - val_acc: 0.0969\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 47s 291ms/step - loss: 0.7900 - acc: 0.8419 - val_loss: 4.8721 - val_acc: 0.1156\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 46s 289ms/step - loss: 0.7344 - acc: 0.8461 - val_loss: 5.1360 - val_acc: 0.1219\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 46s 287ms/step - loss: 0.6386 - acc: 0.8739 - val_loss: 5.1668 - val_acc: 0.1109\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 45s 282ms/step - loss: 0.6127 - acc: 0.8800 - val_loss: 5.0751 - val_acc: 0.1047\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 45s 280ms/step - loss: 0.5667 - acc: 0.8906 - val_loss: 5.6894 - val_acc: 0.1109\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 45s 278ms/step - loss: 0.4942 - acc: 0.9021 - val_loss: 5.6448 - val_acc: 0.0766\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 44s 275ms/step - loss: 0.4336 - acc: 0.9153 - val_loss: 5.3624 - val_acc: 0.0953\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 44s 276ms/step - loss: 0.4039 - acc: 0.9232 - val_loss: 5.6914 - val_acc: 0.0984\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 44s 275ms/step - loss: 0.3851 - acc: 0.9287 - val_loss: 5.5805 - val_acc: 0.1250\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 44s 276ms/step - loss: 0.3035 - acc: 0.9410 - val_loss: 5.9536 - val_acc: 0.0938\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 43s 271ms/step - loss: 0.2836 - acc: 0.9442 - val_loss: 5.8715 - val_acc: 0.1266\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 43s 271ms/step - loss: 0.2355 - acc: 0.9537 - val_loss: 6.1718 - val_acc: 0.0875\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 43s 269ms/step - loss: 0.2379 - acc: 0.9563 - val_loss: 6.3545 - val_acc: 0.1063\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 43s 269ms/step - loss: 0.2147 - acc: 0.9543 - val_loss: 6.4129 - val_acc: 0.1172\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 43s 270ms/step - loss: 0.2001 - acc: 0.9600 - val_loss: 6.8305 - val_acc: 0.0953\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 43s 268ms/step - loss: 0.1507 - acc: 0.9687 - val_loss: 6.4806 - val_acc: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCBokBRToi1J"
      },
      "source": [
        "Model 2 - Add Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OFJxji7kTvi",
        "outputId": "3a762301-51e5-4bc8-e571-d925568947a0"
      },
      "source": [
        "train_datagen_2 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_2 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_2 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_2 = train_datagen_2.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_2 = valid_datagen_2.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 70700 images belonging to 101 classes.\n",
            "Found 20200 images belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RZ-sbV4oSBd",
        "outputId": "199d42e3-0e17-4839-e398-5069f7272612"
      },
      "source": [
        "X_train, y_train = train_generator_2.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_2 = Sequential()\r\n",
        "\r\n",
        "baseline_model_2.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_2.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_2.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_2.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_2.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_2.add(Dense(2048, activation='relu'))\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_2.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 62, 62, 128)       3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 31, 31, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 29, 29, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 2048)              102762496 \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 101)               206949    \n",
            "=================================================================\n",
            "Total params: 103,268,197\n",
            "Trainable params: 103,268,197\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxFkxM4WoR42"
      },
      "source": [
        "opt_2 = Adam()\r\n",
        "\r\n",
        "baseline_model_2.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_2,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6_E0rxBoRxo",
        "outputId": "e8bb8987-0c72-44a1-efe1-64bb5439dd80"
      },
      "source": [
        "X_val, y_val = valid_generator_2.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_2 = baseline_model_2.fit_generator(train_generator_2,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_2,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_2.save('food_baseline_model_2.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 61s 376ms/step - loss: 4.7403 - acc: 0.0175 - val_loss: 4.4713 - val_acc: 0.0422\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 53s 329ms/step - loss: 4.3505 - acc: 0.0550 - val_loss: 4.2506 - val_acc: 0.0578\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 49s 308ms/step - loss: 4.1373 - acc: 0.0773 - val_loss: 4.1307 - val_acc: 0.0953\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 48s 298ms/step - loss: 4.0150 - acc: 0.0935 - val_loss: 4.0741 - val_acc: 0.0859\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 47s 291ms/step - loss: 3.8705 - acc: 0.1175 - val_loss: 3.9456 - val_acc: 0.1203\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 46s 285ms/step - loss: 3.7602 - acc: 0.1384 - val_loss: 3.7741 - val_acc: 0.1469\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 45s 282ms/step - loss: 3.6184 - acc: 0.1676 - val_loss: 3.8375 - val_acc: 0.1312\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 44s 277ms/step - loss: 3.4832 - acc: 0.1913 - val_loss: 3.7611 - val_acc: 0.1484\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 44s 277ms/step - loss: 3.3706 - acc: 0.2178 - val_loss: 3.7188 - val_acc: 0.1375\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 44s 274ms/step - loss: 3.2249 - acc: 0.2427 - val_loss: 3.6179 - val_acc: 0.1641\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 44s 274ms/step - loss: 3.1087 - acc: 0.2776 - val_loss: 3.7926 - val_acc: 0.1500\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 45s 279ms/step - loss: 3.0497 - acc: 0.2986 - val_loss: 3.8581 - val_acc: 0.1375\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 44s 275ms/step - loss: 2.8898 - acc: 0.3379 - val_loss: 3.7164 - val_acc: 0.1672\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 44s 272ms/step - loss: 2.6995 - acc: 0.3780 - val_loss: 3.9203 - val_acc: 0.1578\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 43s 271ms/step - loss: 2.5438 - acc: 0.4059 - val_loss: 4.0151 - val_acc: 0.1578\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 43s 270ms/step - loss: 2.3947 - acc: 0.4482 - val_loss: 4.0189 - val_acc: 0.1594\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 43s 267ms/step - loss: 2.2607 - acc: 0.4760 - val_loss: 4.1153 - val_acc: 0.1500\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 43s 267ms/step - loss: 2.1102 - acc: 0.5174 - val_loss: 3.9772 - val_acc: 0.1625\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 43s 266ms/step - loss: 2.0171 - acc: 0.5460 - val_loss: 4.2139 - val_acc: 0.1609\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 42s 265ms/step - loss: 1.8215 - acc: 0.5831 - val_loss: 4.2031 - val_acc: 0.1500\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 42s 263ms/step - loss: 1.7042 - acc: 0.6086 - val_loss: 4.3468 - val_acc: 0.1625\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 42s 263ms/step - loss: 1.5452 - acc: 0.6565 - val_loss: 4.3595 - val_acc: 0.1312\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 42s 263ms/step - loss: 1.4243 - acc: 0.6805 - val_loss: 4.6280 - val_acc: 0.1437\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 42s 262ms/step - loss: 1.3050 - acc: 0.7150 - val_loss: 4.8945 - val_acc: 0.1250\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 42s 261ms/step - loss: 1.2706 - acc: 0.7197 - val_loss: 4.5997 - val_acc: 0.1516\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 42s 262ms/step - loss: 1.1316 - acc: 0.7513 - val_loss: 4.8343 - val_acc: 0.1437\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 42s 261ms/step - loss: 1.0558 - acc: 0.7686 - val_loss: 4.8471 - val_acc: 0.1375\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 42s 261ms/step - loss: 0.9927 - acc: 0.7847 - val_loss: 5.1454 - val_acc: 0.1609\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 42s 260ms/step - loss: 0.8810 - acc: 0.8023 - val_loss: 4.9520 - val_acc: 0.1781\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 42s 261ms/step - loss: 0.8060 - acc: 0.8258 - val_loss: 4.9533 - val_acc: 0.1344\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 42s 259ms/step - loss: 0.7067 - acc: 0.8408 - val_loss: 5.4085 - val_acc: 0.1281\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 41s 259ms/step - loss: 0.6702 - acc: 0.8540 - val_loss: 5.4166 - val_acc: 0.1719\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 42s 259ms/step - loss: 0.6156 - acc: 0.8702 - val_loss: 5.4623 - val_acc: 0.1453\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 42s 260ms/step - loss: 0.5653 - acc: 0.8724 - val_loss: 5.8284 - val_acc: 0.1375\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 41s 259ms/step - loss: 0.5194 - acc: 0.8911 - val_loss: 6.1091 - val_acc: 0.1391\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 42s 260ms/step - loss: 0.4648 - acc: 0.8965 - val_loss: 5.7589 - val_acc: 0.1266\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 42s 259ms/step - loss: 0.4158 - acc: 0.9085 - val_loss: 6.2249 - val_acc: 0.1469\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 42s 259ms/step - loss: 0.3749 - acc: 0.9169 - val_loss: 6.1742 - val_acc: 0.1406\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 42s 261ms/step - loss: 0.3977 - acc: 0.9111 - val_loss: 6.4858 - val_acc: 0.1187\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 0.3563 - acc: 0.9195 - val_loss: 6.6051 - val_acc: 0.1203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miDNb6sTpbiX"
      },
      "source": [
        "Model 3 - Add Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGlEE6w5oRjY",
        "outputId": "a9d33ae3-abb2-49bf-db12-36e024ce0ff2"
      },
      "source": [
        "train_datagen_3 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_3 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_3 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_3 = train_datagen_3.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_3 = valid_datagen_3.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 70700 images belonging to 101 classes.\n",
            "Found 20200 images belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbM6KH9YpXmw",
        "outputId": "b85fd37b-4512-49f4-86b4-da3f622f17b0"
      },
      "source": [
        "X_train, y_train = train_generator_3.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_3 = Sequential()\r\n",
        "\r\n",
        "baseline_model_3.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_3.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_3.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_3.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_3.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_3.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_3.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_3.add(Dense(2048, activation='relu'))\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_3.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 62, 62, 128)       3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 31, 31, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 29, 29, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 12, 12, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 2048)              37750784  \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 101)               206949    \n",
            "=================================================================\n",
            "Total params: 39,436,645\n",
            "Trainable params: 39,436,645\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEzKtjqqpXkI"
      },
      "source": [
        "opt_3 = Adam()\r\n",
        "\r\n",
        "baseline_model_3.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_3,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGz6Oe8fpXgk",
        "outputId": "b03af864-72a4-412e-e2ef-25357044ef22"
      },
      "source": [
        "X_val, y_val = valid_generator_3.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_3 = baseline_model_3.fit_generator(train_generator_3,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_3,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_3.save('food_baseline_model_3.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 47s 289ms/step - loss: 4.6151 - acc: 0.0163 - val_loss: 4.4683 - val_acc: 0.0234\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 45s 280ms/step - loss: 4.4043 - acc: 0.0411 - val_loss: 4.2801 - val_acc: 0.0578\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 45s 279ms/step - loss: 4.2224 - acc: 0.0677 - val_loss: 4.0473 - val_acc: 0.0812\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 44s 278ms/step - loss: 4.0521 - acc: 0.0943 - val_loss: 3.9126 - val_acc: 0.1125\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 44s 274ms/step - loss: 3.8893 - acc: 0.1140 - val_loss: 3.8385 - val_acc: 0.1281\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 44s 272ms/step - loss: 3.7689 - acc: 0.1340 - val_loss: 3.7478 - val_acc: 0.1406\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 43s 271ms/step - loss: 3.6689 - acc: 0.1468 - val_loss: 3.6272 - val_acc: 0.1578\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 43s 271ms/step - loss: 3.5186 - acc: 0.1727 - val_loss: 3.5463 - val_acc: 0.1969\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 43s 266ms/step - loss: 3.4096 - acc: 0.2051 - val_loss: 3.4517 - val_acc: 0.1906\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 43s 266ms/step - loss: 3.3292 - acc: 0.2195 - val_loss: 3.4730 - val_acc: 0.1937\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 42s 263ms/step - loss: 3.2220 - acc: 0.2317 - val_loss: 3.6495 - val_acc: 0.1766\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 42s 264ms/step - loss: 3.1409 - acc: 0.2516 - val_loss: 3.4827 - val_acc: 0.1984\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 42s 260ms/step - loss: 3.0333 - acc: 0.2762 - val_loss: 3.4391 - val_acc: 0.2109\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 42s 261ms/step - loss: 2.9670 - acc: 0.2939 - val_loss: 3.4646 - val_acc: 0.2031\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 42s 260ms/step - loss: 2.8385 - acc: 0.3141 - val_loss: 3.5051 - val_acc: 0.2078\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 42s 261ms/step - loss: 2.7332 - acc: 0.3425 - val_loss: 3.5439 - val_acc: 0.1937\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 2.6111 - acc: 0.3684 - val_loss: 3.5262 - val_acc: 0.2250\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 2.5269 - acc: 0.3883 - val_loss: 3.3917 - val_acc: 0.2406\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 2.4573 - acc: 0.4170 - val_loss: 3.5233 - val_acc: 0.2062\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 2.3282 - acc: 0.4387 - val_loss: 3.5891 - val_acc: 0.2219\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 2.2137 - acc: 0.4660 - val_loss: 3.3895 - val_acc: 0.2234\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 2.1558 - acc: 0.4801 - val_loss: 3.7554 - val_acc: 0.2000\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 41s 259ms/step - loss: 2.0708 - acc: 0.5103 - val_loss: 3.6847 - val_acc: 0.2297\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.9086 - acc: 0.5366 - val_loss: 3.7684 - val_acc: 0.2156\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.8267 - acc: 0.5657 - val_loss: 3.7521 - val_acc: 0.2234\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 1.6941 - acc: 0.6002 - val_loss: 3.7192 - val_acc: 0.1953\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 1.6558 - acc: 0.6027 - val_loss: 4.0469 - val_acc: 0.1875\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 1.5964 - acc: 0.6233 - val_loss: 4.0631 - val_acc: 0.2000\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 1.4417 - acc: 0.6485 - val_loss: 4.4185 - val_acc: 0.1813\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 1.4084 - acc: 0.6622 - val_loss: 4.2524 - val_acc: 0.1922\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.3084 - acc: 0.6889 - val_loss: 4.3887 - val_acc: 0.1922\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 1.2566 - acc: 0.7021 - val_loss: 4.4596 - val_acc: 0.2000\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 1.1514 - acc: 0.7200 - val_loss: 4.3263 - val_acc: 0.2156\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 1.1073 - acc: 0.7361 - val_loss: 4.6397 - val_acc: 0.1969\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 1.0566 - acc: 0.7457 - val_loss: 4.4345 - val_acc: 0.1969\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 0.9503 - acc: 0.7734 - val_loss: 4.7405 - val_acc: 0.1937\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 0.9240 - acc: 0.7799 - val_loss: 4.9704 - val_acc: 0.1875\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 0.8110 - acc: 0.8043 - val_loss: 5.1041 - val_acc: 0.1781\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 41s 253ms/step - loss: 0.8362 - acc: 0.8034 - val_loss: 5.2165 - val_acc: 0.1844\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 0.7428 - acc: 0.8230 - val_loss: 5.2297 - val_acc: 0.1922\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 0.7147 - acc: 0.8283 - val_loss: 5.2478 - val_acc: 0.1703\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 0.6879 - acc: 0.8312 - val_loss: 5.5224 - val_acc: 0.1828\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 0.5789 - acc: 0.8566 - val_loss: 5.4379 - val_acc: 0.1922\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 0.6054 - acc: 0.8554 - val_loss: 5.4231 - val_acc: 0.1766\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 0.5214 - acc: 0.8697 - val_loss: 5.7131 - val_acc: 0.1891\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 0.5228 - acc: 0.8709 - val_loss: 5.9602 - val_acc: 0.1797\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 0.4905 - acc: 0.8842 - val_loss: 6.2419 - val_acc: 0.1625\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 0.4580 - acc: 0.8848 - val_loss: 5.8877 - val_acc: 0.1797\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 0.4895 - acc: 0.8786 - val_loss: 6.2699 - val_acc: 0.1813\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 0.3988 - acc: 0.8959 - val_loss: 6.3813 - val_acc: 0.1969\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 0.4062 - acc: 0.8971 - val_loss: 6.5028 - val_acc: 0.1906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD1DuF5bp_41"
      },
      "source": [
        "Model 4 - Add more Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7QistASpXQh",
        "outputId": "96ad84a1-c644-4dea-f742-7190c292a2d6"
      },
      "source": [
        "train_datagen_4 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_4 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_4 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_4 = train_datagen_4.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_4 = valid_datagen_4.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 70700 images belonging to 101 classes.\n",
            "Found 20200 images belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RPXk_64oRXK",
        "outputId": "a3947900-758a-44ff-aa28-a2b5542bab7a"
      },
      "source": [
        "X_train, y_train = train_generator_4.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_4 = Sequential()\r\n",
        "\r\n",
        "baseline_model_4.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_4.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_4.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_4.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_4.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_4.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_4.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_4.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_4.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_4.add(Dense(2048, activation='relu'))\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_4.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 62, 62, 128)       3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 31, 31, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 29, 29, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 12, 12, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 4, 4, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 2, 2, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 2048)              8390656   \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 101)               206949    \n",
            "=================================================================\n",
            "Total params: 14,796,133\n",
            "Trainable params: 14,796,133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBs4uIG2qM3r"
      },
      "source": [
        "opt_4 = Adam()\r\n",
        "\r\n",
        "baseline_model_4.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_4,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgdZaB2tqM04",
        "outputId": "c5972128-3458-4772-bce0-dc00adf5270f"
      },
      "source": [
        "X_val, y_val = valid_generator_4.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_4 = baseline_model_4.fit_generator(train_generator_4,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_4,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_4.save('food_baseline_model_4.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 42s 259ms/step - loss: 4.6183 - acc: 0.0140 - val_loss: 4.6127 - val_acc: 0.0125\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 42s 261ms/step - loss: 4.5942 - acc: 0.0119 - val_loss: 4.5132 - val_acc: 0.0109\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 41s 259ms/step - loss: 4.4965 - acc: 0.0241 - val_loss: 4.4274 - val_acc: 0.0250\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 41s 259ms/step - loss: 4.3920 - acc: 0.0373 - val_loss: 4.2900 - val_acc: 0.0453\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 41s 259ms/step - loss: 4.2527 - acc: 0.0516 - val_loss: 4.2213 - val_acc: 0.0437\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 41s 259ms/step - loss: 4.1728 - acc: 0.0714 - val_loss: 4.1479 - val_acc: 0.0734\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.0734 - acc: 0.0771 - val_loss: 4.0608 - val_acc: 0.0797\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 41s 259ms/step - loss: 3.9847 - acc: 0.0896 - val_loss: 3.9823 - val_acc: 0.1016\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 3.9230 - acc: 0.1064 - val_loss: 3.9225 - val_acc: 0.1094\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 42s 259ms/step - loss: 3.8409 - acc: 0.1235 - val_loss: 3.9247 - val_acc: 0.1031\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 3.7401 - acc: 0.1414 - val_loss: 3.8579 - val_acc: 0.1469\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 3.6976 - acc: 0.1428 - val_loss: 3.7524 - val_acc: 0.1234\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 3.6415 - acc: 0.1540 - val_loss: 3.7220 - val_acc: 0.1328\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 3.5573 - acc: 0.1769 - val_loss: 3.7118 - val_acc: 0.1391\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 3.5181 - acc: 0.1778 - val_loss: 3.6009 - val_acc: 0.1672\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 3.4281 - acc: 0.1835 - val_loss: 3.5475 - val_acc: 0.1813\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 3.4132 - acc: 0.1920 - val_loss: 3.5345 - val_acc: 0.1734\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 3.3669 - acc: 0.2049 - val_loss: 3.4374 - val_acc: 0.1891\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 3.2634 - acc: 0.2189 - val_loss: 3.5682 - val_acc: 0.1609\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 3.2113 - acc: 0.2367 - val_loss: 3.4108 - val_acc: 0.2016\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 3.2038 - acc: 0.2377 - val_loss: 3.5134 - val_acc: 0.1922\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 3.1017 - acc: 0.2567 - val_loss: 3.5015 - val_acc: 0.1813\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 3.0375 - acc: 0.2657 - val_loss: 3.3841 - val_acc: 0.2141\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 2.9997 - acc: 0.2755 - val_loss: 3.4762 - val_acc: 0.2172\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 2.9684 - acc: 0.2799 - val_loss: 3.3368 - val_acc: 0.2109\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 2.9565 - acc: 0.2813 - val_loss: 3.3146 - val_acc: 0.2313\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 2.8850 - acc: 0.2950 - val_loss: 3.4457 - val_acc: 0.1813\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 2.8322 - acc: 0.3109 - val_loss: 3.3927 - val_acc: 0.2125\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 2.7974 - acc: 0.3186 - val_loss: 3.4917 - val_acc: 0.2047\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 2.7324 - acc: 0.3259 - val_loss: 3.2860 - val_acc: 0.2234\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 2.6686 - acc: 0.3448 - val_loss: 3.2556 - val_acc: 0.2281\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 2.6279 - acc: 0.3564 - val_loss: 3.3894 - val_acc: 0.2172\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 2.5545 - acc: 0.3681 - val_loss: 3.4247 - val_acc: 0.2313\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 2.5783 - acc: 0.3700 - val_loss: 3.3539 - val_acc: 0.2219\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 2.5144 - acc: 0.3843 - val_loss: 3.2793 - val_acc: 0.2531\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 2.4563 - acc: 0.3854 - val_loss: 3.3540 - val_acc: 0.2297\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 2.3528 - acc: 0.4156 - val_loss: 3.4049 - val_acc: 0.2313\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 2.3480 - acc: 0.4174 - val_loss: 3.4508 - val_acc: 0.2094\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 42s 262ms/step - loss: 2.3413 - acc: 0.4160 - val_loss: 3.5502 - val_acc: 0.1953\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 2.2383 - acc: 0.4488 - val_loss: 3.5448 - val_acc: 0.2125\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 2.2003 - acc: 0.4506 - val_loss: 3.3967 - val_acc: 0.2500\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 2.2085 - acc: 0.4554 - val_loss: 3.5055 - val_acc: 0.2188\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 2.0929 - acc: 0.4664 - val_loss: 3.6898 - val_acc: 0.2188\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 2.0902 - acc: 0.4801 - val_loss: 3.4732 - val_acc: 0.2578\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.9797 - acc: 0.5057 - val_loss: 3.7418 - val_acc: 0.2484\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.9404 - acc: 0.5163 - val_loss: 3.6348 - val_acc: 0.2438\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 1.8971 - acc: 0.5276 - val_loss: 3.8529 - val_acc: 0.2250\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.8883 - acc: 0.5238 - val_loss: 3.6803 - val_acc: 0.2453\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 1.8624 - acc: 0.5231 - val_loss: 3.7373 - val_acc: 0.2234\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.7684 - acc: 0.5607 - val_loss: 3.8650 - val_acc: 0.2141\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.7370 - acc: 0.5516 - val_loss: 3.9543 - val_acc: 0.2172\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 1.6919 - acc: 0.5744 - val_loss: 3.9550 - val_acc: 0.2234\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.6573 - acc: 0.5813 - val_loss: 3.9554 - val_acc: 0.2313\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.6214 - acc: 0.5855 - val_loss: 4.0372 - val_acc: 0.2328\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 1.5838 - acc: 0.5927 - val_loss: 4.0358 - val_acc: 0.2094\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.5070 - acc: 0.6127 - val_loss: 4.1560 - val_acc: 0.2281\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 1.4656 - acc: 0.6299 - val_loss: 4.4558 - val_acc: 0.1844\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 41s 254ms/step - loss: 1.4694 - acc: 0.6230 - val_loss: 3.9151 - val_acc: 0.2219\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 1.3881 - acc: 0.6441 - val_loss: 4.1978 - val_acc: 0.2328\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 1.3556 - acc: 0.6478 - val_loss: 4.5315 - val_acc: 0.2125\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 42s 263ms/step - loss: 1.2892 - acc: 0.6704 - val_loss: 4.4171 - val_acc: 0.2188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSMTDbDiq5y0"
      },
      "source": [
        "Model 5 - Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7QsXdC4qMxD",
        "outputId": "c5da58ea-1ebc-4343-cabc-4e8e7899e9fa"
      },
      "source": [
        "train_datagen_5 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_5 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_5 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_5 = train_datagen_5.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_5 = valid_datagen_5.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 70700 images belonging to 101 classes.\n",
            "Found 20200 images belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjfxikLxqMrv",
        "outputId": "6995cc62-91e8-4eab-87ef-880e63724de1"
      },
      "source": [
        "X_train, y_train = train_generator_5.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_5 = Sequential()\r\n",
        "\r\n",
        "baseline_model_5.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_5.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_5.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_5.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_5.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_5.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_5.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_5.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_5.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_5.add(Dense(2048, activation='relu'))\r\n",
        "baseline_model_5.add(Dense(4096, activation='relu'))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_5.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 62, 62, 128)       3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 31, 31, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 29, 29, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 12, 12, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 4, 4, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 2, 2, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 2048)              8390656   \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 101)               413797    \n",
            "=================================================================\n",
            "Total params: 23,395,685\n",
            "Trainable params: 23,395,685\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx72TkMlqMh0"
      },
      "source": [
        "opt_5 = Adam()\r\n",
        "\r\n",
        "baseline_model_5.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_5,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRikR3d3rEGe",
        "outputId": "37dca2e5-bd85-4f60-8528-edbcfe7fe265"
      },
      "source": [
        "X_val, y_val = valid_generator_5.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_5 = baseline_model_5.fit_generator(train_generator_5,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_5,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_5.save('food_baseline_model_5.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 43s 264ms/step - loss: 4.6190 - acc: 0.0080 - val_loss: 4.6155 - val_acc: 0.0109\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6156 - acc: 0.0090 - val_loss: 4.6156 - val_acc: 0.0063\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6155 - acc: 0.0078 - val_loss: 4.6145 - val_acc: 0.0031\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6153 - acc: 0.0091 - val_loss: 4.6141 - val_acc: 0.0141\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6155 - acc: 0.0089 - val_loss: 4.6147 - val_acc: 0.0094\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 42s 259ms/step - loss: 4.6149 - acc: 0.0108 - val_loss: 4.6164 - val_acc: 0.0109\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6152 - acc: 0.0099 - val_loss: 4.6152 - val_acc: 0.0078\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6153 - acc: 0.0091 - val_loss: 4.6149 - val_acc: 0.0078\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6156 - acc: 0.0092 - val_loss: 4.6143 - val_acc: 0.0156\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6156 - acc: 0.0072 - val_loss: 4.6161 - val_acc: 0.0109\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6159 - acc: 0.0106 - val_loss: 4.6156 - val_acc: 0.0078\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6157 - acc: 0.0106 - val_loss: 4.6154 - val_acc: 0.0141\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6152 - acc: 0.0117 - val_loss: 4.6169 - val_acc: 0.0063\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6151 - acc: 0.0118 - val_loss: 4.6166 - val_acc: 0.0063\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6155 - acc: 0.0108 - val_loss: 4.6141 - val_acc: 0.0141\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6154 - acc: 0.0099 - val_loss: 4.6157 - val_acc: 0.0109\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6158 - acc: 0.0082 - val_loss: 4.6143 - val_acc: 0.0109\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6152 - acc: 0.0080 - val_loss: 4.6158 - val_acc: 0.0109\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6154 - acc: 0.0081 - val_loss: 4.6167 - val_acc: 0.0109\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6160 - acc: 0.0077 - val_loss: 4.6166 - val_acc: 0.0031\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6147 - acc: 0.0092 - val_loss: 4.6149 - val_acc: 0.0047\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6153 - acc: 0.0098 - val_loss: 4.6155 - val_acc: 0.0109\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6152 - acc: 0.0103 - val_loss: 4.6155 - val_acc: 0.0078\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6154 - acc: 0.0086 - val_loss: 4.6146 - val_acc: 0.0156\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6153 - acc: 0.0086 - val_loss: 4.6159 - val_acc: 0.0078\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6155 - acc: 0.0088 - val_loss: 4.6156 - val_acc: 0.0109\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6150 - acc: 0.0132 - val_loss: 4.6142 - val_acc: 0.0125\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6157 - acc: 0.0106 - val_loss: 4.6152 - val_acc: 0.0047\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6155 - acc: 0.0113 - val_loss: 4.6166 - val_acc: 0.0047\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6155 - acc: 0.0091 - val_loss: 4.6137 - val_acc: 0.0172\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6153 - acc: 0.0115 - val_loss: 4.6153 - val_acc: 0.0109\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6155 - acc: 0.0085 - val_loss: 4.6140 - val_acc: 0.0063\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6163 - acc: 0.0098 - val_loss: 4.6156 - val_acc: 0.0063\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6156 - acc: 0.0082 - val_loss: 4.6185 - val_acc: 0.0172\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6148 - acc: 0.0107 - val_loss: 4.6157 - val_acc: 0.0109\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6159 - acc: 0.0083 - val_loss: 4.6172 - val_acc: 0.0188\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6153 - acc: 0.0097 - val_loss: 4.6149 - val_acc: 0.0031\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6151 - acc: 0.0077 - val_loss: 4.6151 - val_acc: 0.0063\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 42s 260ms/step - loss: 4.6157 - acc: 0.0098 - val_loss: 4.6152 - val_acc: 0.0047\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6156 - acc: 0.0108 - val_loss: 4.6163 - val_acc: 0.0094\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6152 - acc: 0.0089 - val_loss: 4.6152 - val_acc: 0.0234\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6154 - acc: 0.0081 - val_loss: 4.6143 - val_acc: 0.0141\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6158 - acc: 0.0092 - val_loss: 4.6152 - val_acc: 0.0172\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6151 - acc: 0.0109 - val_loss: 4.6158 - val_acc: 0.0125\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6157 - acc: 0.0096 - val_loss: 4.6148 - val_acc: 0.0125\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6158 - acc: 0.0088 - val_loss: 4.6155 - val_acc: 0.0172\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6153 - acc: 0.0101 - val_loss: 4.6164 - val_acc: 0.0047\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6152 - acc: 0.0097 - val_loss: 4.6160 - val_acc: 0.0141\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6155 - acc: 0.0099 - val_loss: 4.6155 - val_acc: 0.0094\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6150 - acc: 0.0101 - val_loss: 4.6172 - val_acc: 0.0094\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6152 - acc: 0.0098 - val_loss: 4.6162 - val_acc: 0.0047\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6159 - acc: 0.0115 - val_loss: 4.6159 - val_acc: 0.0109\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6158 - acc: 0.0085 - val_loss: 4.6143 - val_acc: 0.0125\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6152 - acc: 0.0106 - val_loss: 4.6155 - val_acc: 0.0094\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6150 - acc: 0.0124 - val_loss: 4.6148 - val_acc: 0.0141\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6153 - acc: 0.0102 - val_loss: 4.6142 - val_acc: 0.0109\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6154 - acc: 0.0096 - val_loss: 4.6146 - val_acc: 0.0172\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6153 - acc: 0.0114 - val_loss: 4.6158 - val_acc: 0.0125\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6154 - acc: 0.0082 - val_loss: 4.6163 - val_acc: 0.0125\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6157 - acc: 0.0105 - val_loss: 4.6146 - val_acc: 0.0031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye764gy7rdiI"
      },
      "source": [
        "Model 6 - Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4PD76UdrEBb",
        "outputId": "720630ee-90b7-403e-c9ae-8af135a0d004"
      },
      "source": [
        "train_datagen_6 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_6 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_6 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_6 = train_datagen_6.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_6 = valid_datagen_6.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 70700 images belonging to 101 classes.\n",
            "Found 20200 images belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe0hgSTorD7L"
      },
      "source": [
        "X_train, y_train = train_generator_6.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_6 = Sequential()\r\n",
        "\r\n",
        "baseline_model_6.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_6.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_6.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_6.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_6.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_6.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_6.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_6.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_6.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_6.add(Dense(2048, activation='relu'))\r\n",
        "baseline_model_6.add(Dense(4096, activation='relu'))\r\n",
        "baseline_model_6.add(Dense(4096, activation='relu'))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_6.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_6.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6BLVBTyrD3x"
      },
      "source": [
        "opt_6 = Adam()\r\n",
        "\r\n",
        "baseline_model_6.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_6,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWDn__b0rDz9",
        "outputId": "9eccb64b-b525-4c9f-96c5-dd58f4dfb726"
      },
      "source": [
        "X_val, y_val = valid_generator_6.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_6 = baseline_model_6.fit_generator(train_generator_6,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_6,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_6.save('food_baseline_model_6.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 42s 259ms/step - loss: 4.6330 - acc: 0.0099 - val_loss: 4.6164 - val_acc: 0.0125\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 42s 259ms/step - loss: 4.6153 - acc: 0.0102 - val_loss: 4.6153 - val_acc: 0.0125\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6156 - acc: 0.0102 - val_loss: 4.6151 - val_acc: 0.0094\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6155 - acc: 0.0100 - val_loss: 4.6175 - val_acc: 0.0063\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6156 - acc: 0.0096 - val_loss: 4.6150 - val_acc: 0.0078\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6149 - acc: 0.0080 - val_loss: 4.6174 - val_acc: 0.0078\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6155 - acc: 0.0109 - val_loss: 4.6153 - val_acc: 0.0188\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6153 - acc: 0.0105 - val_loss: 4.6156 - val_acc: 0.0125\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6153 - acc: 0.0108 - val_loss: 4.6149 - val_acc: 0.0141\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6155 - acc: 0.0107 - val_loss: 4.6135 - val_acc: 0.0172\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6155 - acc: 0.0073 - val_loss: 4.6144 - val_acc: 0.0156\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6153 - acc: 0.0106 - val_loss: 4.6151 - val_acc: 0.0141\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6155 - acc: 0.0105 - val_loss: 4.6156 - val_acc: 0.0000e+00\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6156 - acc: 0.0111 - val_loss: 4.6163 - val_acc: 0.0047\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6154 - acc: 0.0098 - val_loss: 4.6153 - val_acc: 0.0109\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6157 - acc: 0.0081 - val_loss: 4.6150 - val_acc: 0.0063\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6158 - acc: 0.0090 - val_loss: 4.6152 - val_acc: 0.0141\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6159 - acc: 0.0110 - val_loss: 4.6157 - val_acc: 0.0125\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6157 - acc: 0.0101 - val_loss: 4.6153 - val_acc: 0.0047\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6155 - acc: 0.0094 - val_loss: 4.6154 - val_acc: 0.0047\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6154 - acc: 0.0095 - val_loss: 4.6146 - val_acc: 0.0078\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6155 - acc: 0.0087 - val_loss: 4.6148 - val_acc: 0.0172\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6152 - acc: 0.0087 - val_loss: 4.6157 - val_acc: 0.0047\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6151 - acc: 0.0121 - val_loss: 4.6155 - val_acc: 0.0094\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6154 - acc: 0.0143 - val_loss: 4.6147 - val_acc: 0.0031\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6153 - acc: 0.0107 - val_loss: 4.6157 - val_acc: 0.0094\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6157 - acc: 0.0092 - val_loss: 4.6161 - val_acc: 0.0125\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6161 - acc: 0.0100 - val_loss: 4.6149 - val_acc: 0.0094\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6154 - acc: 0.0096 - val_loss: 4.6158 - val_acc: 0.0078\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 4.6155 - acc: 0.0090 - val_loss: 4.6140 - val_acc: 0.0125\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6154 - acc: 0.0099 - val_loss: 4.6160 - val_acc: 0.0078\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6156 - acc: 0.0095 - val_loss: 4.6145 - val_acc: 0.0047\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6154 - acc: 0.0101 - val_loss: 4.6152 - val_acc: 0.0078\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6153 - acc: 0.0100 - val_loss: 4.6138 - val_acc: 0.0094\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6157 - acc: 0.0099 - val_loss: 4.6153 - val_acc: 0.0109\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6159 - acc: 0.0103 - val_loss: 4.6136 - val_acc: 0.0125\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6153 - acc: 0.0116 - val_loss: 4.6154 - val_acc: 0.0094\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 4.6151 - acc: 0.0089 - val_loss: 4.6153 - val_acc: 0.0141\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 4.6152 - acc: 0.0101 - val_loss: 4.6135 - val_acc: 0.0141\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 4.6159 - acc: 0.0074 - val_loss: 4.6157 - val_acc: 0.0141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LD_KlL-tKXL"
      },
      "source": [
        "Model 7 - Add Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m-QJLKYrDv2",
        "outputId": "e5893af7-b09d-4034-9c55-a2f43e380165"
      },
      "source": [
        "train_datagen_7 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_7 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_7 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_7 = train_datagen_7.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_7 = valid_datagen_7.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 70700 images belonging to 101 classes.\n",
            "Found 20200 images belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jv5rh4IrDsK",
        "outputId": "5e063cb5-9147-4284-b5cd-c8c5bbe25041"
      },
      "source": [
        "X_train, y_train = train_generator_7.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_7 = Sequential()\r\n",
        "\r\n",
        "baseline_model_7.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_7.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_7.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_7.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_7.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_7.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_7.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_7.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_7.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_7.add(Dense(2048, activation='relu'))\r\n",
        "baseline_model_7.add(Dropout(0.2))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_7.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_7.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 62, 62, 128)       3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 31, 31, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 29, 29, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              8390656   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 101)               206949    \n",
            "=================================================================\n",
            "Total params: 14,796,133\n",
            "Trainable params: 14,796,133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ3wbN3-sfOW"
      },
      "source": [
        "opt_7 = Adam()\r\n",
        "\r\n",
        "baseline_model_7.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_7,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peCgNieuskcB",
        "outputId": "a4bd1b74-5b9d-479c-eee9-3999b06428e8"
      },
      "source": [
        "X_val, y_val = valid_generator_7.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_7 = baseline_model_7.fit_generator(train_generator_7,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_7,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_7.save('food_baseline_model_7.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 73s 409ms/step - loss: 4.6211 - acc: 0.0096 - val_loss: 4.6162 - val_acc: 0.0063\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 62s 384ms/step - loss: 4.6154 - acc: 0.0099 - val_loss: 4.6158 - val_acc: 0.0109\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 59s 369ms/step - loss: 4.6155 - acc: 0.0098 - val_loss: 4.6155 - val_acc: 0.0109\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 57s 356ms/step - loss: 4.6152 - acc: 0.0117 - val_loss: 4.6155 - val_acc: 0.0109\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 56s 350ms/step - loss: 4.6156 - acc: 0.0093 - val_loss: 4.6154 - val_acc: 0.0141\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 55s 342ms/step - loss: 4.6155 - acc: 0.0108 - val_loss: 4.6155 - val_acc: 0.0109\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 54s 335ms/step - loss: 4.6154 - acc: 0.0100 - val_loss: 4.6160 - val_acc: 0.0078\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 53s 330ms/step - loss: 4.6154 - acc: 0.0104 - val_loss: 4.6156 - val_acc: 0.0078\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 52s 323ms/step - loss: 4.6154 - acc: 0.0110 - val_loss: 4.6157 - val_acc: 0.0047\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 51s 319ms/step - loss: 4.6152 - acc: 0.0110 - val_loss: 4.6166 - val_acc: 0.0109\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 51s 318ms/step - loss: 4.6158 - acc: 0.0097 - val_loss: 4.6160 - val_acc: 0.0047\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 51s 321ms/step - loss: 4.6155 - acc: 0.0121 - val_loss: 4.6148 - val_acc: 0.0125\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 51s 316ms/step - loss: 4.6152 - acc: 0.0108 - val_loss: 4.6170 - val_acc: 0.0094\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 51s 320ms/step - loss: 4.6158 - acc: 0.0091 - val_loss: 4.6143 - val_acc: 0.0156\n",
            "Epoch 15/100\n",
            " 95/160 [================>.............] - ETA: 19s - loss: 4.6152 - acc: 0.0095"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NywPVdS7uNoe"
      },
      "source": [
        "Model 8 - Increase Dropout Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRR4m14DskVB",
        "outputId": "83cac831-6a2f-4d3c-87ac-e0d29ed2bb47"
      },
      "source": [
        "train_datagen_8 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_8 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_8 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_8 = train_datagen_8.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_8 = valid_datagen_8.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 70700 images belonging to 101 classes.\n",
            "Found 20200 images belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EaOFWhYskOA"
      },
      "source": [
        "X_train, y_train = train_generator_8.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_8 = Sequential()\r\n",
        "\r\n",
        "baseline_model_8.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_8.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_8.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_8.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_8.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_8.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_8.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_8.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_8.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_8.add(Dense(2048, activation='relu'))\r\n",
        "baseline_model_8.add(Dropout(0.3))\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_8.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_8.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "YxRH7IbPskF_",
        "outputId": "d549b94b-465d-48d6-97f7-e63d893fcf90"
      },
      "source": [
        "opt_8 = Adam()\r\n",
        "\r\n",
        "baseline_model_8.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_8,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-ceb4acfc4eac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mopt_8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m baseline_model_8.compile(loss='categorical_crossentropy',\n\u001b[0m\u001b[1;32m      4\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               metrics=['acc'])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'baseline_model_8' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lsvck5Fsj91"
      },
      "source": [
        "X_val, y_val = valid_generator_8.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_8 = baseline_model_8.fit_generator(train_generator_8,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_8,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_8.save('food_baseline_model_8.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWBh3SbpvAOR"
      },
      "source": [
        "Model 9 - Add Kernel Constraint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSooXnNlsj0K"
      },
      "source": [
        "train_datagen_9 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_9 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_9 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_9 = train_datagen_9.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_9 = valid_datagen_9.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGbABl79u_lt"
      },
      "source": [
        "X_train, y_train = train_generator_9.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_9 = Sequential()\r\n",
        "\r\n",
        "baseline_model_9.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_9.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_9.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_9.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_9.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_9.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_9.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_9.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_9.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_9.add(Dense(2048, activation='relu',kernel_constraint=maxnorm(3)))\r\n",
        "baseline_model_9.add(Dropout(0.3))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_9.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_9.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3msRhJjFu_h-"
      },
      "source": [
        "opt_9 = Adam()\r\n",
        "\r\n",
        "baseline_model_9.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_9,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJLM-0W0u_ei"
      },
      "source": [
        "X_val, y_val = valid_generator_9.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_9 = baseline_model_9.fit_generator(train_generator_9,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_9,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_9.save('food_baseline_model_9.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca1og51Wx1Xa"
      },
      "source": [
        "Model 10 - Add learning rate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvH0OR6xu_ax"
      },
      "source": [
        "train_datagen_10 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_10 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_10 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_10 = train_datagen_10.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_10 = valid_datagen_10.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l2hWxDCu_XU"
      },
      "source": [
        "X_train, y_train = train_generator_10.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_10 = Sequential()\r\n",
        "\r\n",
        "baseline_model_10.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_10.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_10.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_10.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_10.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_10.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_10.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_10.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_10.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_10.add(Dense(2048, activation='relu',kernel_constraint=maxnorm(3)))\r\n",
        "baseline_model_10.add(Dropout(0.3))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_10.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_10.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlHiXuhGu_Rz"
      },
      "source": [
        "opt_10 = Adam(lr=0.001)\r\n",
        "\r\n",
        "baseline_model_10.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_10,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwEjGFv6u_Ns"
      },
      "source": [
        "X_val, y_val = valid_generator_10.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_10 = baseline_model_10.fit_generator(train_generator_10,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_10,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_10.save('food_baseline_model_10.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI0MWpYCzqrB"
      },
      "source": [
        "Model 11 - Change optimizer to RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRZIYXXku_I1"
      },
      "source": [
        "train_datagen_11 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_11 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_11 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_11 = train_datagen_11.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_11 = valid_datagen_11.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "688kC6s-u_C1"
      },
      "source": [
        "X_train, y_train = train_generator_11.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_11 = Sequential()\r\n",
        "\r\n",
        "baseline_model_11.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_11.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_11.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_11.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_11.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_11.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_11.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_11.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_11.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_11.add(Dense(2048, activation='relu',kernel_constraint=maxnorm(3)))\r\n",
        "baseline_model_11.add(Dropout(0.3))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_11.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_11.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwQfV-AOsfKY"
      },
      "source": [
        "opt_11 = RMSprop(lr=0.001)\r\n",
        "\r\n",
        "baseline_model_11.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_11,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxyXKkqOsfGP"
      },
      "source": [
        "X_val, y_val = valid_generator_11.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_11 = baseline_model_11.fit_generator(train_generator_11,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_11,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_11.save('food_baseline_model_11.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE2yI5_l1vfO"
      },
      "source": [
        "Model 12 - Increase Batch Size + Steps per epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y61k7tmPz7x2"
      },
      "source": [
        "train_datagen_12 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_12 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_12 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_12 = train_datagen_12.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=128,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_12 = valid_datagen_12.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=128,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVrEUyNkz7uD"
      },
      "source": [
        "X_train, y_train = train_generator_12.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_12 = Sequential()\r\n",
        "\r\n",
        "baseline_model_12.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_12.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_12.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_12.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_12.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_12.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_12.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_12.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_12.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_12.add(Dense(2048, activation='relu',kernel_constraint=maxnorm(3)))\r\n",
        "baseline_model_12.add(Dropout(0.3))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_12.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_12.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLCgjpTGz7ri"
      },
      "source": [
        "opt_12 = RMSprop(lr=0.001)\r\n",
        "\r\n",
        "baseline_model_12.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_12,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txzAD2SWz7ov"
      },
      "source": [
        "X_val, y_val = valid_generator_12.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_12 = baseline_model_12.fit_generator(train_generator_12,\r\n",
        "                              steps_per_epoch=320, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_12,\r\n",
        "                              validation_steps=32, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_12.save('food_baseline_model_12.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue_61CzS22PW"
      },
      "source": [
        "Model 13 - Change padding (Worse Results)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IClZwOGXz7lh"
      },
      "source": [
        "train_datagen_13 = ImageDataGenerator(\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_13 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_13 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_13 = train_datagen_13.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=128,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_13 = valid_datagen_13.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=128,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq9DT1DS2iVr"
      },
      "source": [
        "X_train, y_train = train_generator_13.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_13 = Sequential()\r\n",
        "\r\n",
        "baseline_model_13.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_13.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_13.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))\r\n",
        "baseline_model_13.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_13.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'))\r\n",
        "baseline_model_13.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_13.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='same'))\r\n",
        "baseline_model_13.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_13.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_13.add(Dense(2048, activation='relu',kernel_constraint=maxnorm(3)))\r\n",
        "baseline_model_13.add(Dropout(0.3))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_13.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_13.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdLrhIoY2iSH"
      },
      "source": [
        "opt_13 = RMSprop(lr=0.001)\r\n",
        "\r\n",
        "baseline_model_13.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_13,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU1qSgfM2iO7"
      },
      "source": [
        "X_val, y_val = valid_generator_13.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_13 = baseline_model_13.fit_generator(train_generator_13,\r\n",
        "                              steps_per_epoch=320, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_13,\r\n",
        "                              validation_steps=32, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_13.save('food_baseline_model_13.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLqTZ7m92-mK"
      },
      "source": [
        "Model 14 - Include Data Augmentation techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIk3wwAx2iLM"
      },
      "source": [
        "train_datagen_14 = ImageDataGenerator(samplewise_center = True,\r\n",
        "                                  samplewise_std_normalization = True,\r\n",
        "                                  rescale = 1./255.)\r\n",
        "\r\n",
        "valid_datagen_14 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_14 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_14 = train_datagen_14.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=128,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_14 = valid_datagen_14.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=128,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpSQjwDL2iIS"
      },
      "source": [
        "X_train, y_train = train_generator_14.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_14 = Sequential()\r\n",
        "\r\n",
        "baseline_model_14.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_14.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_14.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_14.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_14.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_14.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_14.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_14.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_14.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_14.add(Dense(2048, activation='relu',kernel_constraint=maxnorm(3)))\r\n",
        "baseline_model_14.add(Dropout(0.3))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_14.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_14.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qfU0osT2iCh"
      },
      "source": [
        "opt_14 = RMSprop(lr=0.001)\r\n",
        "\r\n",
        "baseline_model_14.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_14,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UycMYs8qz7iN"
      },
      "source": [
        "X_val, y_val = valid_generator_14.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_14 = baseline_model_14.fit_generator(train_generator_14,\r\n",
        "                              steps_per_epoch=320, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_14,\r\n",
        "                              validation_steps=32, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_14.save('food_baseline_model_14.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAAM1hcT5jyN"
      },
      "source": [
        "Model 15 - More Data Augmentation techniques\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HZWDJk15NWu"
      },
      "source": [
        "train_datagen_15 = ImageDataGenerator(samplewise_center = True,\r\n",
        "                                  samplewise_std_normalization = True,\r\n",
        "                                  rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True))\r\n",
        "\r\n",
        "valid_datagen_15 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen_15 = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator_15 = train_datagen_15.flow_from_directory(directory=\"/content/output/train\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=128,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator_15 = valid_datagen_15.flow_from_directory(directory=\"/content/output/val\",\r\n",
        "                                                  batch_size=128,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOzZMn-p5NRj"
      },
      "source": [
        "X_train, y_train = train_generator_15.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model_15 = Sequential()\r\n",
        "\r\n",
        "baseline_model_15.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model_15.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_15.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_15.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_15.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_15.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model_15.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model_15.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model_15.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model_15.add(Dense(2048, activation='relu',kernel_constraint=maxnorm(3)))\r\n",
        "baseline_model_15.add(Dropout(0.3))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model_15.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model_15.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj_hkP-C5NOd"
      },
      "source": [
        "opt_15 = RMSprop(lr=0.001)\r\n",
        "\r\n",
        "baseline_model_15.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt_15,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Ibdb7r5NLn"
      },
      "source": [
        "X_val, y_val = valid_generator_15.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model_15 = baseline_model_15.fit_generator(train_generator_15,\r\n",
        "                              steps_per_epoch=320, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator_15,\r\n",
        "                              validation_steps=32, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model_15.save('food_baseline_model_15.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5_jK77m5NIy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xhiIpwL5NGF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49v2Sqdt5NDT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tci4DDul5NAK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7LuuH5_5M9P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie_O_6I_5M6g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FErdiXlt5M31"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnS460PB5M0-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i28md_Mm5MyK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3E0RrbV5MuW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH1hzBwq5Mqy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "Yj9wjWbUoIbo",
        "outputId": "8c75d577-dc01-4ec9-9971-f07f24710cbc"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\r\n",
        "                                  samplewise_center = True,\r\n",
        "                                  samplewise_std_normalization = True,\r\n",
        "                                  rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\r\n",
        "\r\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory=\"/output/train/\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=64,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(64,64),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "valid_generator=test_datagen.flow_from_directory(directory=\"/output/val/\",\r\n",
        "                                                  subset=\"validation\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)\r\n",
        "\r\n",
        "\r\n",
        "teste=test_datagen.flow_from_directory(directory=\"/output/test\",\r\n",
        "                                                  subset=\"test\",\r\n",
        "                                                  batch_size=64,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(64,64),\r\n",
        "                                                  seed=42)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6b1c82cda679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                     \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                                     seed=42)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtest_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         )\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/output/images/train/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gh2LsAZ0dSG",
        "outputId": "27b54f80-0d8c-487c-ea70-81e96f997408"
      },
      "source": [
        "\r\n",
        "\r\n",
        "X_train, y_train = train_generator.next()\r\n",
        "#Input Layer\r\n",
        "baseline_model = Sequential()\r\n",
        "\r\n",
        "baseline_model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=X_train.shape[1:]))\r\n",
        "baseline_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "baseline_model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "\r\n",
        "baseline_model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "\r\n",
        "baseline_model.add(Conv2D(filters=1024, kernel_size=(3, 3), activation='relu', padding='valid'))\r\n",
        "baseline_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\r\n",
        "\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model.add(Dense(4096, activation='relu',kernel_constraint=maxnorm(3)))\r\n",
        "baseline_model.add(Dropout(0.2))\r\n",
        "baseline_model.add(Dense(4096, activation='relu',kernel_constraint=maxnorm(3)))\r\n",
        "baseline_model.add(Dropout(0.2))\r\n",
        "baseline_model.add(Dense(2048, activation='relu',kernel_constraint=maxnorm(3)))\r\n",
        "baseline_model.add(Dropout(0.2))\r\n",
        "\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model.add(Dense(y_train.shape[1], activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_110 (Conv2D)          (None, 62, 62, 128)       3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 31, 31, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_111 (Conv2D)          (None, 29, 29, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 12, 12, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_113 (Conv2D)          (None, 4, 4, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 2, 2, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 2048)              8390656   \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 101)               206949    \n",
            "=================================================================\n",
            "Total params: 48,358,757\n",
            "Trainable params: 48,358,757\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24SOh5Al3p1p"
      },
      "source": [
        "opt = Adam(lr=0.001)\r\n",
        "\r\n",
        "baseline_model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt,\r\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulUsdn3k0dPu",
        "outputId": "b1ab8b45-9fc0-4e12-b953-edfe8a3af3db"
      },
      "source": [
        "X_val, y_val = valid_generator.next()\r\n",
        "early_stop = EarlyStopping(patience=30, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "\r\n",
        "history_baseline_model = baseline_model_1.fit_generator(train_generator,\r\n",
        "                              steps_per_epoch=160, #steps_per_epoch,\r\n",
        "                              epochs=100,\r\n",
        "                              validation_data=valid_generator,\r\n",
        "                              validation_steps=10, #validation_steps,\r\n",
        "                              callbacks=[early_stop],\r\n",
        "                              shuffle= True\r\n",
        "                             )\r\n",
        "\r\n",
        "baseline_model.save('food_baseline_model_1.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 4.2930 - acc: 0.0545 - val_loss: 4.3365 - val_acc: 0.0547\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 4.2158 - acc: 0.0665 - val_loss: 4.3475 - val_acc: 0.0453\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 4.1883 - acc: 0.0685 - val_loss: 4.1274 - val_acc: 0.0656\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 4.1421 - acc: 0.0763 - val_loss: 4.0769 - val_acc: 0.0734\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 4.1097 - acc: 0.0757 - val_loss: 4.1044 - val_acc: 0.0812\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 4.0798 - acc: 0.0794 - val_loss: 4.1218 - val_acc: 0.0734\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 4.0663 - acc: 0.0854 - val_loss: 4.0138 - val_acc: 0.1000\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 54s 335ms/step - loss: 4.0106 - acc: 0.0966 - val_loss: 3.9263 - val_acc: 0.0891\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 3.9844 - acc: 0.1031 - val_loss: 3.9202 - val_acc: 0.0891\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.9832 - acc: 0.0984 - val_loss: 4.0941 - val_acc: 0.1000\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 54s 335ms/step - loss: 3.9288 - acc: 0.1095 - val_loss: 3.9572 - val_acc: 0.1000\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 54s 335ms/step - loss: 3.8888 - acc: 0.1178 - val_loss: 3.8715 - val_acc: 0.1016\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.8843 - acc: 0.1187 - val_loss: 3.8528 - val_acc: 0.1250\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 54s 335ms/step - loss: 3.8519 - acc: 0.1239 - val_loss: 3.8808 - val_acc: 0.1266\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 54s 335ms/step - loss: 3.8553 - acc: 0.1282 - val_loss: 4.0839 - val_acc: 0.0953\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 3.8585 - acc: 0.1199 - val_loss: 3.9523 - val_acc: 0.1078\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 54s 335ms/step - loss: 3.8105 - acc: 0.1344 - val_loss: 3.8526 - val_acc: 0.1266\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 53s 333ms/step - loss: 3.8053 - acc: 0.1354 - val_loss: 3.7849 - val_acc: 0.1281\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 54s 335ms/step - loss: 3.8055 - acc: 0.1369 - val_loss: 3.8160 - val_acc: 0.1281\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 3.7894 - acc: 0.1396 - val_loss: 3.6900 - val_acc: 0.1578\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 3.7647 - acc: 0.1380 - val_loss: 3.6681 - val_acc: 0.1531\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.7385 - acc: 0.1454 - val_loss: 3.9261 - val_acc: 0.1312\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.7372 - acc: 0.1427 - val_loss: 3.7062 - val_acc: 0.1625\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 3.7475 - acc: 0.1476 - val_loss: 3.7471 - val_acc: 0.1453\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.7225 - acc: 0.1499 - val_loss: 3.6470 - val_acc: 0.1391\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.7364 - acc: 0.1487 - val_loss: 3.6801 - val_acc: 0.1578\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 54s 340ms/step - loss: 3.7397 - acc: 0.1479 - val_loss: 3.6127 - val_acc: 0.1391\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.7415 - acc: 0.1485 - val_loss: 3.6862 - val_acc: 0.1641\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 54s 340ms/step - loss: 3.7275 - acc: 0.1490 - val_loss: 3.5305 - val_acc: 0.1813\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 55s 341ms/step - loss: 3.7150 - acc: 0.1545 - val_loss: 3.7019 - val_acc: 0.1562\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 55s 342ms/step - loss: 3.7403 - acc: 0.1534 - val_loss: 3.6834 - val_acc: 0.1500\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 55s 341ms/step - loss: 3.7102 - acc: 0.1492 - val_loss: 3.6855 - val_acc: 0.1719\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 54s 340ms/step - loss: 3.7081 - acc: 0.1602 - val_loss: 3.6563 - val_acc: 0.1500\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.7134 - acc: 0.1541 - val_loss: 3.6173 - val_acc: 0.1578\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.6994 - acc: 0.1601 - val_loss: 3.5260 - val_acc: 0.1766\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.7694 - acc: 0.1483 - val_loss: 3.6450 - val_acc: 0.1766\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 3.6951 - acc: 0.1599 - val_loss: 3.7911 - val_acc: 0.1516\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.7352 - acc: 0.1548 - val_loss: 3.5834 - val_acc: 0.1844\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 55s 341ms/step - loss: 3.7420 - acc: 0.1489 - val_loss: 3.6774 - val_acc: 0.1734\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.7121 - acc: 0.1542 - val_loss: 3.8230 - val_acc: 0.1562\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.7355 - acc: 0.1551 - val_loss: 3.5215 - val_acc: 0.2000\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.7138 - acc: 0.1552 - val_loss: 3.7669 - val_acc: 0.1453\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.7268 - acc: 0.1546 - val_loss: 3.8007 - val_acc: 0.1453\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 54s 340ms/step - loss: 3.7079 - acc: 0.1582 - val_loss: 3.7697 - val_acc: 0.1531\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.7805 - acc: 0.1458 - val_loss: 3.6400 - val_acc: 0.1734\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.7019 - acc: 0.1584 - val_loss: 3.5901 - val_acc: 0.1688\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.7050 - acc: 0.1586 - val_loss: 3.6296 - val_acc: 0.1875\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.7206 - acc: 0.1636 - val_loss: 3.6511 - val_acc: 0.1703\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.7301 - acc: 0.1519 - val_loss: 3.6634 - val_acc: 0.1547\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 54s 340ms/step - loss: 3.7418 - acc: 0.1559 - val_loss: 3.5576 - val_acc: 0.1688\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.7279 - acc: 0.1598 - val_loss: 3.6099 - val_acc: 0.1813\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.7423 - acc: 0.1487 - val_loss: 3.7685 - val_acc: 0.1359\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.7293 - acc: 0.1509 - val_loss: 3.5707 - val_acc: 0.1578\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.7431 - acc: 0.1555 - val_loss: 3.6244 - val_acc: 0.1781\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.7510 - acc: 0.1467 - val_loss: 3.6414 - val_acc: 0.1797\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.8016 - acc: 0.1446 - val_loss: 3.5118 - val_acc: 0.1953\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.7569 - acc: 0.1528 - val_loss: 3.6398 - val_acc: 0.1594\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 3.7680 - acc: 0.1535 - val_loss: 3.7780 - val_acc: 0.1625\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.7913 - acc: 0.1433 - val_loss: 3.7635 - val_acc: 0.1594\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.8628 - acc: 0.1344 - val_loss: 3.8536 - val_acc: 0.1422\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.7635 - acc: 0.1507 - val_loss: 3.5256 - val_acc: 0.1750\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.8198 - acc: 0.1453 - val_loss: 4.0548 - val_acc: 0.1234\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.8040 - acc: 0.1491 - val_loss: 3.5750 - val_acc: 0.1672\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 3.7937 - acc: 0.1505 - val_loss: 3.8417 - val_acc: 0.1203\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 55s 341ms/step - loss: 3.8364 - acc: 0.1385 - val_loss: 3.7733 - val_acc: 0.1562\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 55s 344ms/step - loss: 3.8185 - acc: 0.1432 - val_loss: 3.8386 - val_acc: 0.1516\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 55s 345ms/step - loss: 3.8317 - acc: 0.1385 - val_loss: 3.7958 - val_acc: 0.1516\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 56s 349ms/step - loss: 3.8166 - acc: 0.1424 - val_loss: 3.7081 - val_acc: 0.1562\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 55s 342ms/step - loss: 3.8158 - acc: 0.1431 - val_loss: 3.8014 - val_acc: 0.1594\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.8192 - acc: 0.1446 - val_loss: 3.8521 - val_acc: 0.1406\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.8430 - acc: 0.1350 - val_loss: 3.7000 - val_acc: 0.1547\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 55s 341ms/step - loss: 3.8431 - acc: 0.1388 - val_loss: 3.6782 - val_acc: 0.1734\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 54s 341ms/step - loss: 3.8360 - acc: 0.1401 - val_loss: 3.6813 - val_acc: 0.1766\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 3.8216 - acc: 0.1383 - val_loss: 4.6390 - val_acc: 0.1344\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.8187 - acc: 0.1433 - val_loss: 3.6964 - val_acc: 0.1156\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.8077 - acc: 0.1435 - val_loss: 3.6240 - val_acc: 0.1766\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.8371 - acc: 0.1459 - val_loss: 3.7304 - val_acc: 0.1484\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.8415 - acc: 0.1459 - val_loss: 3.9189 - val_acc: 0.1437\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.8734 - acc: 0.1382 - val_loss: 3.8586 - val_acc: 0.1172\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.8851 - acc: 0.1325 - val_loss: 3.8580 - val_acc: 0.1266\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.8540 - acc: 0.1351 - val_loss: 3.6267 - val_acc: 0.1500\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.8512 - acc: 0.1395 - val_loss: 3.6816 - val_acc: 0.1641\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 3.8525 - acc: 0.1404 - val_loss: 3.8742 - val_acc: 0.1063\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 3.8692 - acc: 0.1359 - val_loss: 3.6280 - val_acc: 0.1625\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 55s 341ms/step - loss: 3.8847 - acc: 0.1312 - val_loss: 3.8435 - val_acc: 0.1359\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 3.8707 - acc: 0.1396 - val_loss: 3.6929 - val_acc: 0.1547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSBLC1Uf0dM5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4D1lrAo0dKZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka3V6WPU0dHo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcRaNTnT0dDo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LoPwBDB0dAg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2oW4aeI0c4W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrgOz-j-0cs_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCj9jC5aERPZ",
        "outputId": "e59e0fb1-05a0-4b9f-d983-f2465f235e29"
      },
      "source": [
        "incnet = InceptionV3(weights='imagenet', include_top=False, input_tensor=layers.Input(shape=(299, 299, 3)))\r\n",
        "x = incnet.output\r\n",
        "x = layers.AveragePooling2D(pool_size=(8, 8))(x)\r\n",
        "x = layers.Dropout(.2)(x)\r\n",
        "x = layers.Flatten()(x)\r\n",
        "output = layers.Dense(101, activation='softmax', kernel_regularizer=regularizers.l2(.0005))(x)\r\n",
        "\r\n",
        "model = models.Model(inputs=incnet.input, outputs=output)\r\n",
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqS1V0ObHhcz",
        "outputId": "94cffeef-4532-4807-9ce6-d9421b47f0b2"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMnwx2_VHjDy",
        "outputId": "847469dc-ccfa-4379-fb8b-506b2ff63c1d"
      },
      "source": [
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4)\r\n",
        "checkpoint_callback = ModelCheckpoint('InceptionNet.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\r\n",
        "history = model.fit_generator(train_generator,\r\n",
        "                            validation_data=valid_generator,\r\n",
        "                            epochs=10,\r\n",
        "                            workers=0,\r\n",
        "                            use_multiprocessing=False, \r\n",
        "                            callbacks=[early_stopping_callback, checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1263/1263 [==============================] - 1739s 1s/step - loss: 2.8844 - accuracy: 0.3382 - val_loss: 2.6619 - val_accuracy: 0.3891\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.66189, saving model to InceptionNet.h5\n",
            "Epoch 2/10\n",
            "1263/1263 [==============================] - 1675s 1s/step - loss: 1.4509 - accuracy: 0.6439 - val_loss: 2.6808 - val_accuracy: 0.4057\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 2.66189\n",
            "Epoch 3/10\n",
            "1263/1263 [==============================] - 1638s 1s/step - loss: 1.1333 - accuracy: 0.7240 - val_loss: 1.8525 - val_accuracy: 0.5699\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.66189 to 1.85251, saving model to InceptionNet.h5\n",
            "Epoch 4/10\n",
            "1263/1263 [==============================] - 1615s 1s/step - loss: 0.9297 - accuracy: 0.7748 - val_loss: 2.3600 - val_accuracy: 0.4794\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.85251\n",
            "Epoch 5/10\n",
            "1263/1263 [==============================] - 1600s 1s/step - loss: 0.7756 - accuracy: 0.8156 - val_loss: 1.8512 - val_accuracy: 0.5752\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.85251 to 1.85121, saving model to InceptionNet.h5\n",
            "Epoch 6/10\n",
            "1263/1263 [==============================] - 1576s 1s/step - loss: 0.6716 - accuracy: 0.8430 - val_loss: 2.0550 - val_accuracy: 0.5553\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.85121\n",
            "Epoch 7/10\n",
            "1263/1263 [==============================] - 1586s 1s/step - loss: 0.5669 - accuracy: 0.8716 - val_loss: 1.5541 - val_accuracy: 0.6615\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.85121 to 1.55413, saving model to InceptionNet.h5\n",
            "Epoch 8/10\n",
            "1263/1263 [==============================] - 1593s 1s/step - loss: 0.4740 - accuracy: 0.8973 - val_loss: 1.8449 - val_accuracy: 0.5967\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.55413\n",
            "Epoch 9/10\n",
            "1263/1263 [==============================] - 1575s 1s/step - loss: 0.4182 - accuracy: 0.9116 - val_loss: 2.1094 - val_accuracy: 0.5749\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.55413\n",
            "Epoch 10/10\n",
            "1263/1263 [==============================] - 1593s 1s/step - loss: 0.3734 - accuracy: 0.9240 - val_loss: 1.6664 - val_accuracy: 0.6562\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.55413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhP-Yb3T8V9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8d5ebf-96b2-4d3e-fc05-4f8ba540c070"
      },
      "source": [
        "train_datagen = ImageDataGenerator(#data_format='channels_first',\r\n",
        "                                  validation_split=0.2,\r\n",
        "                                  samplewise_center = True,\r\n",
        "                                  samplewise_std_normalization = True,rescale = 1.0/255.)\r\n",
        "\r\n",
        "train_datageno = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory=\"/content/images\",\r\n",
        "                                                    subset=\"training\",\r\n",
        "                                                    batch_size=20,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "                                                    target_size=(224,224),\r\n",
        "                                                    seed=42)\r\n",
        "\r\n",
        "valid_generator=train_datagen.flow_from_directory(directory=\"/content/images\",\r\n",
        "                                                  subset=\"validation\",\r\n",
        "                                                  batch_size=20,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  class_mode=\"categorical\",\r\n",
        "                                                  target_size=(224,224),\r\n",
        "                                                  seed=42)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 80800 images belonging to 101 classes.\n",
            "Found 20200 images belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV8BgNKg_pX8"
      },
      "source": [
        "train_datageno.fit(train_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaPfhC2H9KUy"
      },
      "source": [
        "train_generator\r\n",
        "\r\n",
        "valid_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_02c-wY9oXi"
      },
      "source": [
        "#IMAGE AUGMENTATION\r\n",
        "\r\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\r\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\r\n",
        "\r\n",
        "# Note that the validation data should not be augmented!\r\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoYnP06t90UU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aab97e9-97ea-4f72-a9fd-2015313e2d87"
      },
      "source": [
        "#TRAINING\r\n",
        "\r\n",
        "# Flow training images in batches of 20 using train_datagen generator\r\n",
        "train_generator = train_datagen.flow_from_directory(directory=\"/content/output/train\", batch_size = 20, class_mode = 'categorical', target_size = (224, 224))\r\n",
        "\r\n",
        "# Flow validation images in batches of 20 using test_datagen generator\r\n",
        "validation_generator = test_datagen.flow_from_directory(directory=\"/content/output/val\",  batch_size = 20, class_mode = 'categorical', target_size = (224, 224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 80800 images belonging to 101 classes.\n",
            "Found 20200 images belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn7T0OTtYH9X"
      },
      "source": [
        "#NOVO PROJETO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_YMJw-OYHHH"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import matplotlib.image as img\r\n",
        "%matplotlib inline\r\n",
        "import numpy as np\r\n",
        "from collections import defaultdict\r\n",
        "import collections\r\n",
        "from shutil import copy\r\n",
        "from shutil import copytree, rmtree\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import random\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "from tensorflow.keras import regularizers\r\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\r\n",
        "from tensorflow.keras.models import Sequential, Model\r\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\r\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\r\n",
        "from tensorflow.keras.optimizers import SGD\r\n",
        "from tensorflow.keras.regularizers import l2\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import models\r\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DBXuBB1YpKe"
      },
      "source": [
        "# Helper method to create train_mini and test_mini data samples\r\n",
        "def dataset_mini(food_list, src, dest):\r\n",
        "  if os.path.exists(dest):\r\n",
        "    rmtree(dest) # removing dataset_mini(if it already exists) folders so that we will have only the classes that we want\r\n",
        "  os.makedirs(dest)\r\n",
        "  for food_item in food_list :\r\n",
        "    print(\"Copying images into\",food_item)\r\n",
        "    copytree(os.path.join(src,food_item), os.path.join(dest,food_item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rub3rI5JYqAd"
      },
      "source": [
        "food_list = ['apple_pie','pizza','omelette']\r\n",
        "src_train = '/content/output/train'\r\n",
        "dest_train = '/content/output/train_mini'\r\n",
        "src_test = '/content/output/val'\r\n",
        "dest_test = '/content/output/val_mini'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j2v4yf1YuTo",
        "outputId": "de2d8c33-8e1e-4b0e-f44c-1db3df558e13"
      },
      "source": [
        "print(\"Creating train data folder with new classes\")\r\n",
        "dataset_mini(food_list, src_train, dest_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating train data folder with new classes\n",
            "Copying images into apple_pie\n",
            "Copying images into pizza\n",
            "Copying images into omelette\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEUIlRZrZluW",
        "outputId": "ed08b9b0-1204-4bc6-cee5-f116ef097481"
      },
      "source": [
        "print(\"Total number of samples in train folder\")\r\n",
        "\r\n",
        "!find /content/output/train_mini -type d -or -type f -printf '.' | wc -c\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of samples in train folder\n",
            "2400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiCLhXisaAl0",
        "outputId": "c7152a01-1ec1-4a6e-af9e-d3e6fdad8893"
      },
      "source": [
        "\r\n",
        "\r\n",
        "print(\"Creating test data folder with new classes\")\r\n",
        "dataset_mini(food_list, src_test, dest_test)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating test data folder with new classes\n",
            "Copying images into apple_pie\n",
            "Copying images into pizza\n",
            "Copying images into omelette\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6r9eXEUacLj",
        "outputId": "54d50a5a-bf53-40e7-e056-f122d6784019"
      },
      "source": [
        "print(\"Total number of samples in test folder\")\r\n",
        "!find /content/output/val_mini -type d -or -type f -printf '.' | wc -c\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of samples in test folder\n",
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMmnPuRTat7d",
        "outputId": "a296224e-1044-48c4-8d22-b872576de206"
      },
      "source": [
        "K.clear_session()\r\n",
        "n_classes = 3\r\n",
        "img_width, img_height = 299, 299\r\n",
        "train_data_dir = '/content/output/train_mini'\r\n",
        "validation_data_dir = '/content/output/val_mini'\r\n",
        "nb_train_samples = 2400 #75750\r\n",
        "nb_validation_samples = 600 #25250\r\n",
        "batch_size = 16\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    rescale=1. / 255,\r\n",
        "    shear_range=0.2,\r\n",
        "    zoom_range=0.2,\r\n",
        "    horizontal_flip=True)\r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "    train_data_dir,\r\n",
        "    target_size=(img_height, img_width),\r\n",
        "    batch_size=batch_size,\r\n",
        "    class_mode='categorical')\r\n",
        "\r\n",
        "validation_generator = test_datagen.flow_from_directory(\r\n",
        "    validation_data_dir,\r\n",
        "    target_size=(img_height, img_width),\r\n",
        "    batch_size=batch_size,\r\n",
        "    class_mode='categorical')\r\n",
        "\r\n",
        "\r\n",
        "inception = InceptionV3(weights='imagenet', include_top=False)\r\n",
        "x = inception.output\r\n",
        "x = GlobalAveragePooling2D()(x)\r\n",
        "x = Dense(128,activation='relu')(x)\r\n",
        "x = Dropout(0.2)(x)\r\n",
        "\r\n",
        "predictions = Dense(3,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\r\n",
        "\r\n",
        "model = Model(inputs=inception.input, outputs=predictions)\r\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "checkpointer = ModelCheckpoint(filepath='best_model_3class.hdf5', verbose=1, save_best_only=True)\r\n",
        "csv_logger = CSVLogger('history_3class.log')\r\n",
        "\r\n",
        "history = model.fit_generator(train_generator,\r\n",
        "                    steps_per_epoch = nb_train_samples // batch_size,\r\n",
        "                    validation_data=validation_generator,\r\n",
        "                    validation_steps=nb_validation_samples // batch_size,\r\n",
        "                    epochs=30,\r\n",
        "                    verbose=1,\r\n",
        "                    callbacks=[csv_logger, checkpointer])\r\n",
        "\r\n",
        "model.save('model_trained_3class.hdf5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2400 images belonging to 3 classes.\n",
            "Found 600 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "150/150 [==============================] - 74s 442ms/step - loss: 1.1282 - accuracy: 0.4067 - val_loss: 0.8111 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.81108, saving model to best_model_3class.hdf5\n",
            "Epoch 2/30\n",
            "150/150 [==============================] - 65s 432ms/step - loss: 0.8120 - accuracy: 0.6959 - val_loss: 0.6171 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.81108 to 0.61714, saving model to best_model_3class.hdf5\n",
            "Epoch 3/30\n",
            "150/150 [==============================] - 65s 433ms/step - loss: 0.6302 - accuracy: 0.7828 - val_loss: 0.4980 - val_accuracy: 0.8429\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.61714 to 0.49803, saving model to best_model_3class.hdf5\n",
            "Epoch 4/30\n",
            "150/150 [==============================] - 65s 434ms/step - loss: 0.5057 - accuracy: 0.8249 - val_loss: 0.4307 - val_accuracy: 0.8530\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.49803 to 0.43072, saving model to best_model_3class.hdf5\n",
            "Epoch 5/30\n",
            "150/150 [==============================] - 65s 432ms/step - loss: 0.4414 - accuracy: 0.8528 - val_loss: 0.3887 - val_accuracy: 0.8682\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.43072 to 0.38873, saving model to best_model_3class.hdf5\n",
            "Epoch 6/30\n",
            "150/150 [==============================] - 64s 428ms/step - loss: 0.3861 - accuracy: 0.8760 - val_loss: 0.3487 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.38873 to 0.34866, saving model to best_model_3class.hdf5\n",
            "Epoch 7/30\n",
            "150/150 [==============================] - 64s 425ms/step - loss: 0.3607 - accuracy: 0.8894 - val_loss: 0.3374 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.34866 to 0.33739, saving model to best_model_3class.hdf5\n",
            "Epoch 8/30\n",
            "150/150 [==============================] - 64s 424ms/step - loss: 0.3264 - accuracy: 0.8945 - val_loss: 0.3246 - val_accuracy: 0.8868\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.33739 to 0.32456, saving model to best_model_3class.hdf5\n",
            "Epoch 9/30\n",
            "150/150 [==============================] - 64s 425ms/step - loss: 0.3041 - accuracy: 0.8975 - val_loss: 0.3151 - val_accuracy: 0.8936\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.32456 to 0.31511, saving model to best_model_3class.hdf5\n",
            "Epoch 10/30\n",
            "150/150 [==============================] - 64s 423ms/step - loss: 0.2846 - accuracy: 0.9082 - val_loss: 0.2976 - val_accuracy: 0.8970\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.31511 to 0.29762, saving model to best_model_3class.hdf5\n",
            "Epoch 11/30\n",
            "150/150 [==============================] - 64s 423ms/step - loss: 0.2636 - accuracy: 0.9179 - val_loss: 0.2966 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.29762 to 0.29656, saving model to best_model_3class.hdf5\n",
            "Epoch 12/30\n",
            "150/150 [==============================] - 64s 423ms/step - loss: 0.2295 - accuracy: 0.9268 - val_loss: 0.2885 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.29656 to 0.28855, saving model to best_model_3class.hdf5\n",
            "Epoch 13/30\n",
            "150/150 [==============================] - 63s 422ms/step - loss: 0.2206 - accuracy: 0.9366 - val_loss: 0.2874 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.28855 to 0.28742, saving model to best_model_3class.hdf5\n",
            "Epoch 14/30\n",
            "150/150 [==============================] - 64s 426ms/step - loss: 0.2234 - accuracy: 0.9255 - val_loss: 0.2800 - val_accuracy: 0.9037\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.28742 to 0.28002, saving model to best_model_3class.hdf5\n",
            "Epoch 15/30\n",
            "150/150 [==============================] - 64s 425ms/step - loss: 0.2030 - accuracy: 0.9368 - val_loss: 0.2745 - val_accuracy: 0.9071\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.28002 to 0.27449, saving model to best_model_3class.hdf5\n",
            "Epoch 16/30\n",
            "150/150 [==============================] - 64s 424ms/step - loss: 0.1816 - accuracy: 0.9455 - val_loss: 0.2807 - val_accuracy: 0.9071\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.27449\n",
            "Epoch 17/30\n",
            "150/150 [==============================] - 64s 423ms/step - loss: 0.1822 - accuracy: 0.9529 - val_loss: 0.2749 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.27449\n",
            "Epoch 18/30\n",
            "150/150 [==============================] - 64s 425ms/step - loss: 0.1610 - accuracy: 0.9544 - val_loss: 0.2744 - val_accuracy: 0.9155\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.27449 to 0.27441, saving model to best_model_3class.hdf5\n",
            "Epoch 19/30\n",
            "150/150 [==============================] - 64s 427ms/step - loss: 0.1672 - accuracy: 0.9482 - val_loss: 0.2733 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.27441 to 0.27330, saving model to best_model_3class.hdf5\n",
            "Epoch 20/30\n",
            "150/150 [==============================] - 64s 424ms/step - loss: 0.1654 - accuracy: 0.9517 - val_loss: 0.2765 - val_accuracy: 0.9155\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.27330\n",
            "Epoch 21/30\n",
            "150/150 [==============================] - 64s 423ms/step - loss: 0.1414 - accuracy: 0.9660 - val_loss: 0.2750 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.27330\n",
            "Epoch 22/30\n",
            "150/150 [==============================] - 64s 424ms/step - loss: 0.1507 - accuracy: 0.9619 - val_loss: 0.2729 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.27330 to 0.27288, saving model to best_model_3class.hdf5\n",
            "Epoch 23/30\n",
            "150/150 [==============================] - 64s 424ms/step - loss: 0.1270 - accuracy: 0.9691 - val_loss: 0.2817 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.27288\n",
            "Epoch 24/30\n",
            "150/150 [==============================] - 64s 424ms/step - loss: 0.1339 - accuracy: 0.9702 - val_loss: 0.2642 - val_accuracy: 0.9223\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.27288 to 0.26419, saving model to best_model_3class.hdf5\n",
            "Epoch 25/30\n",
            "150/150 [==============================] - 64s 425ms/step - loss: 0.1213 - accuracy: 0.9708 - val_loss: 0.2761 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.26419\n",
            "Epoch 26/30\n",
            "150/150 [==============================] - 64s 423ms/step - loss: 0.1034 - accuracy: 0.9803 - val_loss: 0.2730 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.26419\n",
            "Epoch 27/30\n",
            "150/150 [==============================] - 64s 424ms/step - loss: 0.1191 - accuracy: 0.9684 - val_loss: 0.2831 - val_accuracy: 0.9172\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.26419\n",
            "Epoch 28/30\n",
            "150/150 [==============================] - 64s 424ms/step - loss: 0.1030 - accuracy: 0.9768 - val_loss: 0.2751 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.26419\n",
            "Epoch 29/30\n",
            "150/150 [==============================] - 64s 423ms/step - loss: 0.0950 - accuracy: 0.9789 - val_loss: 0.2841 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.26419\n",
            "Epoch 30/30\n",
            "150/150 [==============================] - 64s 424ms/step - loss: 0.0953 - accuracy: 0.9846 - val_loss: 0.2787 - val_accuracy: 0.9155\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.26419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJN9qKjxjFmN",
        "outputId": "ea95dc6e-cd58-4520-a878-f4a0dbaf5504"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\r\n",
        "\r\n",
        "baseline_model = Sequential()\r\n",
        "\r\n",
        "baseline_model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1,1), activation='relu', padding='valid', input_shape=(299, 299, 3)))\r\n",
        "baseline_model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "baseline_model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1,1), activation='relu', padding='valid'))\r\n",
        "baseline_model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "# MLP - input layer:\r\n",
        "baseline_model.add(Flatten())\r\n",
        "# MLP - hidden layer:\r\n",
        "baseline_model.add(Dense(128, activation='relu'))\r\n",
        "# MLP - output layer:\r\n",
        "baseline_model.add(Dense(101, activation='softmax'))\r\n",
        "\r\n",
        "# Check built model:\r\n",
        "baseline_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 297, 297, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 148, 148, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 146, 146, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 170528)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               21827712  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 101)               13029     \n",
            "=================================================================\n",
            "Total params: 21,850,885\n",
            "Trainable params: 21,850,885\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V3EIXyxra3z"
      },
      "source": [
        "baseline_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\r\n",
        "\r\n",
        "# Common attributes:\r\n",
        "steps_per_epoch = 10\r\n",
        "epochs = 1000\r\n",
        "validation_steps = 10\r\n",
        "patience=30\r\n",
        "shuffle=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKg1f8K8tdMo",
        "outputId": "2b4e1036-0036-444a-85e2-2a05c0fee494"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1. / 255)\r\n",
        "\r\n",
        "train_generator=train_datagen.flow_from_directory(\r\n",
        "                   \r\n",
        "                    directory=\"/content/output/train\",\r\n",
        "                    batch_size=100,\r\n",
        "                    seed=55551,\r\n",
        "                    shuffle=True,\r\n",
        "                    \r\n",
        "                    class_mode=\"categorical\",\r\n",
        "                    target_size=(299,299))\r\n",
        "\r\n",
        "valid_generator=train_datagen.flow_from_directory(\r\n",
        "                    \r\n",
        "                    directory=\"/content/output/val\",\r\n",
        "                    batch_size=100,\r\n",
        "                    seed=55551,\r\n",
        "                    shuffle=True,\r\n",
        "                  \r\n",
        "                    class_mode=\"categorical\",\r\n",
        "                    target_size=(299,299))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 80800 images belonging to 101 classes.\n",
            "Found 20200 images belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeQlyjuJrlav",
        "outputId": "4a9a919d-999e-4024-e6b7-54c42e4d79fd"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "\r\n",
        "early_stop = EarlyStopping(patience=patience, monitor='val_loss', mode='min', restore_best_weights=True)\r\n",
        "\r\n",
        "history_baseline_model = baseline_model.fit_generator(train_generator,\r\n",
        "                                                      steps_per_epoch=steps_per_epoch,\r\n",
        "                                                      validation_data=valid_generator,\r\n",
        "                                                      validation_steps=validation_steps,\r\n",
        "                                                      epochs=epochs,\r\n",
        "                                                      callbacks=[early_stop],\r\n",
        "                                                      shuffle=shuffle\r\n",
        "                                                     ) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "10/10 [==============================] - 23s 2s/step - loss: 8.0918 - acc: 0.0106 - val_loss: 4.6579 - val_acc: 0.0170\n",
            "Epoch 2/1000\n",
            "10/10 [==============================] - 14s 1s/step - loss: 4.6411 - acc: 0.0019 - val_loss: 4.6135 - val_acc: 0.0140\n",
            "Epoch 3/1000\n",
            "10/10 [==============================] - 14s 1s/step - loss: 4.6148 - acc: 0.0167 - val_loss: 4.6103 - val_acc: 0.0120\n",
            "Epoch 4/1000\n",
            "10/10 [==============================] - 14s 1s/step - loss: 4.6083 - acc: 0.0298 - val_loss: 4.6050 - val_acc: 0.0150\n",
            "Epoch 5/1000\n",
            "10/10 [==============================] - 13s 1s/step - loss: 4.6106 - acc: 0.0118 - val_loss: 4.6015 - val_acc: 0.0180\n",
            "Epoch 6/1000\n",
            "10/10 [==============================] - 13s 1s/step - loss: 4.5967 - acc: 0.0138 - val_loss: 4.5945 - val_acc: 0.0160\n",
            "Epoch 7/1000\n",
            "10/10 [==============================] - 13s 1s/step - loss: 4.5939 - acc: 0.0145 - val_loss: 4.5628 - val_acc: 0.0170\n",
            "Epoch 8/1000\n",
            "10/10 [==============================] - 13s 1s/step - loss: 4.5685 - acc: 0.0207 - val_loss: 4.5628 - val_acc: 0.0270\n",
            "Epoch 9/1000\n",
            "10/10 [==============================] - 13s 1s/step - loss: 4.5595 - acc: 0.0197 - val_loss: 4.5724 - val_acc: 0.0230\n",
            "Epoch 10/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.5665 - acc: 0.0258 - val_loss: 4.5373 - val_acc: 0.0310\n",
            "Epoch 11/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.5378 - acc: 0.0175 - val_loss: 4.5583 - val_acc: 0.0230\n",
            "Epoch 12/1000\n",
            "10/10 [==============================] - 13s 1s/step - loss: 4.5586 - acc: 0.0204 - val_loss: 4.5526 - val_acc: 0.0150\n",
            "Epoch 13/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.5109 - acc: 0.0204 - val_loss: 4.5462 - val_acc: 0.0230\n",
            "Epoch 14/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.4902 - acc: 0.0373 - val_loss: 4.5052 - val_acc: 0.0290\n",
            "Epoch 15/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.4945 - acc: 0.0338 - val_loss: 4.4776 - val_acc: 0.0390\n",
            "Epoch 16/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.4732 - acc: 0.0355 - val_loss: 4.4834 - val_acc: 0.0280\n",
            "Epoch 17/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.4691 - acc: 0.0319 - val_loss: 4.4394 - val_acc: 0.0310\n",
            "Epoch 18/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.4838 - acc: 0.0308 - val_loss: 4.4858 - val_acc: 0.0300\n",
            "Epoch 19/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.4642 - acc: 0.0232 - val_loss: 4.4611 - val_acc: 0.0390\n",
            "Epoch 20/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.3957 - acc: 0.0450 - val_loss: 4.4670 - val_acc: 0.0340\n",
            "Epoch 21/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.4423 - acc: 0.0380 - val_loss: 4.4387 - val_acc: 0.0520\n",
            "Epoch 22/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.3429 - acc: 0.0437 - val_loss: 4.4819 - val_acc: 0.0410\n",
            "Epoch 23/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.3926 - acc: 0.0506 - val_loss: 4.3600 - val_acc: 0.0510\n",
            "Epoch 24/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.3512 - acc: 0.0460 - val_loss: 4.4147 - val_acc: 0.0500\n",
            "Epoch 25/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.3307 - acc: 0.0690 - val_loss: 4.4001 - val_acc: 0.0510\n",
            "Epoch 26/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.3299 - acc: 0.0534 - val_loss: 4.3481 - val_acc: 0.0490\n",
            "Epoch 27/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.3146 - acc: 0.0785 - val_loss: 4.3515 - val_acc: 0.0540\n",
            "Epoch 28/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.2607 - acc: 0.0755 - val_loss: 4.3597 - val_acc: 0.0410\n",
            "Epoch 29/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.2684 - acc: 0.0684 - val_loss: 4.3014 - val_acc: 0.0620\n",
            "Epoch 30/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.2167 - acc: 0.0765 - val_loss: 4.3005 - val_acc: 0.0570\n",
            "Epoch 31/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.2419 - acc: 0.0898 - val_loss: 4.3766 - val_acc: 0.0410\n",
            "Epoch 32/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.2071 - acc: 0.0860 - val_loss: 4.3481 - val_acc: 0.0460\n",
            "Epoch 33/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.1594 - acc: 0.1032 - val_loss: 4.3074 - val_acc: 0.0480\n",
            "Epoch 34/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.1004 - acc: 0.1149 - val_loss: 4.3498 - val_acc: 0.0640\n",
            "Epoch 35/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.0807 - acc: 0.1017 - val_loss: 4.2770 - val_acc: 0.0740\n",
            "Epoch 36/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.1686 - acc: 0.1147 - val_loss: 4.3212 - val_acc: 0.0640\n",
            "Epoch 37/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.0796 - acc: 0.0961 - val_loss: 4.3119 - val_acc: 0.0650\n",
            "Epoch 38/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.0280 - acc: 0.1209 - val_loss: 4.2254 - val_acc: 0.0750\n",
            "Epoch 39/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.9736 - acc: 0.1284 - val_loss: 4.2641 - val_acc: 0.0770\n",
            "Epoch 40/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.0713 - acc: 0.1023 - val_loss: 4.1933 - val_acc: 0.0670\n",
            "Epoch 41/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.0594 - acc: 0.0975 - val_loss: 4.2463 - val_acc: 0.0720\n",
            "Epoch 42/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.9562 - acc: 0.1307 - val_loss: 4.2136 - val_acc: 0.0650\n",
            "Epoch 43/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.0166 - acc: 0.1284 - val_loss: 4.2344 - val_acc: 0.0580\n",
            "Epoch 44/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.9125 - acc: 0.1378 - val_loss: 4.2519 - val_acc: 0.0580\n",
            "Epoch 45/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.9201 - acc: 0.1635 - val_loss: 4.2016 - val_acc: 0.0710\n",
            "Epoch 46/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.9720 - acc: 0.1309 - val_loss: 4.2178 - val_acc: 0.0800\n",
            "Epoch 47/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.9124 - acc: 0.1410 - val_loss: 4.1788 - val_acc: 0.0810\n",
            "Epoch 48/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.8279 - acc: 0.1626 - val_loss: 4.1866 - val_acc: 0.0780\n",
            "Epoch 49/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.8513 - acc: 0.1694 - val_loss: 4.2515 - val_acc: 0.0710\n",
            "Epoch 50/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.8394 - acc: 0.1499 - val_loss: 4.2056 - val_acc: 0.0790\n",
            "Epoch 51/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.7454 - acc: 0.1789 - val_loss: 4.1885 - val_acc: 0.0800\n",
            "Epoch 52/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.7875 - acc: 0.1646 - val_loss: 4.1999 - val_acc: 0.0960\n",
            "Epoch 53/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.7216 - acc: 0.1813 - val_loss: 4.3013 - val_acc: 0.0740\n",
            "Epoch 54/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.7164 - acc: 0.2056 - val_loss: 4.2257 - val_acc: 0.0770\n",
            "Epoch 55/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.8254 - acc: 0.1640 - val_loss: 4.2379 - val_acc: 0.0780\n",
            "Epoch 56/1000\n",
            "10/10 [==============================] - 12s 1s/step - loss: 3.8048 - acc: 0.1608 - val_loss: 4.1730 - val_acc: 0.0850\n",
            "Epoch 57/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.6773 - acc: 0.2068 - val_loss: 4.2284 - val_acc: 0.0800\n",
            "Epoch 58/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.7645 - acc: 0.2013 - val_loss: 4.2072 - val_acc: 0.0760\n",
            "Epoch 59/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.5288 - acc: 0.2287 - val_loss: 4.3022 - val_acc: 0.0720\n",
            "Epoch 60/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.7024 - acc: 0.1937 - val_loss: 4.2573 - val_acc: 0.0750\n",
            "Epoch 61/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.5749 - acc: 0.2251 - val_loss: 4.1548 - val_acc: 0.0950\n",
            "Epoch 62/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.6350 - acc: 0.2145 - val_loss: 4.2436 - val_acc: 0.0880\n",
            "Epoch 63/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.5083 - acc: 0.2335 - val_loss: 4.1864 - val_acc: 0.1030\n",
            "Epoch 64/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.5864 - acc: 0.2383 - val_loss: 4.3112 - val_acc: 0.0790\n",
            "Epoch 65/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.5237 - acc: 0.2406 - val_loss: 4.2222 - val_acc: 0.1020\n",
            "Epoch 66/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.5552 - acc: 0.2300 - val_loss: 4.2255 - val_acc: 0.0790\n",
            "Epoch 67/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.4801 - acc: 0.2837 - val_loss: 4.3075 - val_acc: 0.0780\n",
            "Epoch 68/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.5954 - acc: 0.2419 - val_loss: 4.2470 - val_acc: 0.0890\n",
            "Epoch 69/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.4463 - acc: 0.2670 - val_loss: 4.1071 - val_acc: 0.1120\n",
            "Epoch 70/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.3872 - acc: 0.2965 - val_loss: 4.3043 - val_acc: 0.0870\n",
            "Epoch 71/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.3264 - acc: 0.2670 - val_loss: 4.2269 - val_acc: 0.0840\n",
            "Epoch 72/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.2686 - acc: 0.2920 - val_loss: 4.1715 - val_acc: 0.0880\n",
            "Epoch 73/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.3118 - acc: 0.2733 - val_loss: 4.2591 - val_acc: 0.0820\n",
            "Epoch 74/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.2501 - acc: 0.2934 - val_loss: 4.2520 - val_acc: 0.0860\n",
            "Epoch 75/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.2836 - acc: 0.2803 - val_loss: 4.3053 - val_acc: 0.0870\n",
            "Epoch 76/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.1090 - acc: 0.3155 - val_loss: 4.2951 - val_acc: 0.0930\n",
            "Epoch 77/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.2406 - acc: 0.2944 - val_loss: 4.3430 - val_acc: 0.0890\n",
            "Epoch 78/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.2875 - acc: 0.3050 - val_loss: 4.2426 - val_acc: 0.0890\n",
            "Epoch 79/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.1790 - acc: 0.3312 - val_loss: 4.2755 - val_acc: 0.0900\n",
            "Epoch 80/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.2192 - acc: 0.3179 - val_loss: 4.1505 - val_acc: 0.0960\n",
            "Epoch 81/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.0384 - acc: 0.3691 - val_loss: 4.1679 - val_acc: 0.0870\n",
            "Epoch 82/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.1791 - acc: 0.3270 - val_loss: 4.2358 - val_acc: 0.0980\n",
            "Epoch 83/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.1107 - acc: 0.3451 - val_loss: 4.3043 - val_acc: 0.0820\n",
            "Epoch 84/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.0125 - acc: 0.3328 - val_loss: 4.2743 - val_acc: 0.0990\n",
            "Epoch 85/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.0817 - acc: 0.3647 - val_loss: 4.1521 - val_acc: 0.1110\n",
            "Epoch 86/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.9843 - acc: 0.3681 - val_loss: 4.2973 - val_acc: 0.0910\n",
            "Epoch 87/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.0167 - acc: 0.3670 - val_loss: 4.2551 - val_acc: 0.1070\n",
            "Epoch 88/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.9887 - acc: 0.3465 - val_loss: 4.2164 - val_acc: 0.1040\n",
            "Epoch 89/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 3.1338 - acc: 0.3260 - val_loss: 4.2206 - val_acc: 0.0910\n",
            "Epoch 90/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.9280 - acc: 0.3805 - val_loss: 4.3019 - val_acc: 0.0940\n",
            "Epoch 91/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.9450 - acc: 0.3616 - val_loss: 4.2841 - val_acc: 0.0910\n",
            "Epoch 92/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.8035 - acc: 0.4154 - val_loss: 4.2557 - val_acc: 0.0940\n",
            "Epoch 93/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.8710 - acc: 0.3908 - val_loss: 4.3550 - val_acc: 0.0880\n",
            "Epoch 94/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.8114 - acc: 0.3940 - val_loss: 4.2070 - val_acc: 0.1020\n",
            "Epoch 95/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.8815 - acc: 0.3919 - val_loss: 4.2943 - val_acc: 0.0990\n",
            "Epoch 96/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.7793 - acc: 0.3849 - val_loss: 4.3895 - val_acc: 0.1020\n",
            "Epoch 97/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.7339 - acc: 0.4321 - val_loss: 4.2087 - val_acc: 0.0970\n",
            "Epoch 98/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.8253 - acc: 0.4136 - val_loss: 4.3663 - val_acc: 0.0950\n",
            "Epoch 99/1000\n",
            "10/10 [==============================] - 11s 1s/step - loss: 2.7324 - acc: 0.4422 - val_loss: 4.3112 - val_acc: 0.1060\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}